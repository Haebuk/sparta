{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1주차 Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM/qRJESTGBnpPYe6qjXun2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Haebuk/sparta_ML/blob/main/1%EC%A3%BC%EC%B0%A8_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVPv9JNyGXww"
      },
      "source": [
        "## Kaggle Data Load"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84P5dJ2lXzrL"
      },
      "source": [
        "import os\n",
        "os.environ['KAGGLE_USERNAME'] = 'haebuk' # username\n",
        "os.environ['KAGGLE_KEY'] = '012556a132f44be2d63242c5ac5178d4' # key"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WqCo8KOzXncU",
        "outputId": "7b5f1e40-6af2-4c08-fa30-72949e9b2487"
      },
      "source": [
        "!kaggle datasets download -d rsadiq/salary\n",
        "!unzip salary.zip"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "salary.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "Archive:  salary.zip\n",
            "replace Salary.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5YFLvcO2GdK8"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFvVaFtLXuJo"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from tensorflow.keras.losses import MeanAbsoluteError\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt \n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "id": "9_2_iCuQX-kD",
        "outputId": "7d42b055-fb7a-42dd-a191-97d3db46fed6"
      },
      "source": [
        "df = pd.read_csv('Salary.csv')\n",
        "print(df.shape)\n",
        "df.head()"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(35, 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>YearsExperience</th>\n",
              "      <th>Salary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.1</td>\n",
              "      <td>39343</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.3</td>\n",
              "      <td>46205</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.5</td>\n",
              "      <td>37731</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2.0</td>\n",
              "      <td>43525</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.2</td>\n",
              "      <td>39891</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   YearsExperience  Salary\n",
              "0              1.1   39343\n",
              "1              1.3   46205\n",
              "2              1.5   37731\n",
              "3              2.0   43525\n",
              "4              2.2   39891"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vpK_q5mGmg3"
      },
      "source": [
        "## EDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "4P-CFOweYChY",
        "outputId": "cf1070ad-a1dc-471a-d464-79929177f85a"
      },
      "source": [
        "plt.scatter(df['YearsExperience'], df['Salary'])\n",
        "plt.show()"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "As2VyY5aGrs1"
      },
      "source": [
        "- 경력과 연봉간에 선형관계가 있는 것 처럼 보임\n",
        "- 선형회귀모형 적합"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mxuo_2aQYMiL",
        "outputId": "77bda0f8-0dd4-4709-aec7-8cfaedd2dd35"
      },
      "source": [
        "X = np.array(df['YearsExperience'], dtype=np.float32)\n",
        "y = np.array(df['Salary'], dtype=np.float32)\n",
        "y = np.log1p(y) # y값이 커서 log 스케일링\n",
        "\n",
        "X = X.reshape((-1, 1))\n",
        "y = y.reshape((-1, 1))\n",
        "\n",
        "print(X.shape, y.shape)"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(35, 1) (35, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3MSAlOIGzUL"
      },
      "source": [
        "## Split Train Valid Dataset \n",
        "- 원래는 train - valid - test로 나누는게 맞으나, 데이터 사이즈가 매우 작으므로(35개) train과 valid로만 분리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YzC3GCBzYfzD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e67647d-1024-435b-e8fc-489b945be4ac"
      },
      "source": [
        "train_X, valid_X, train_y, valid_y = train_test_split(X, y, test_size=0.2, random_state=2021)\n",
        "print(train_X.shape, train_y.shape)\n",
        "print(valid_X.shape, valid_y.shape)"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(28, 1) (28, 1)\n",
            "(7, 1) (7, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISzAbExLHj5e"
      },
      "source": [
        "## Modeling\n",
        "- 손실함수(loss): MAE\n",
        "- optimizer: SGD, Adam 2가지로 진행"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cpr80f4tIPyr"
      },
      "source": [
        "### Model 1\n",
        "- SGD, lr = 0.05\n",
        "- epochs = 300 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6OlMNG1iHRqX",
        "outputId": "90aa444b-a4b8-4565-96e4-5c7677265e70"
      },
      "source": [
        "model = Sequential([\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "model.compile(loss = 'mae', optimizer=SGD(learning_rate=0.05))\n",
        "\n",
        "model.fit(train_X,\n",
        "          train_y,\n",
        "          validation_data=(valid_X, valid_y),\n",
        "          epochs=300)\n"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "1/1 [==============================] - 0s 305ms/step - loss: 13.4368 - val_loss: 11.0136\n",
            "Epoch 2/300\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 11.1494 - val_loss: 9.3630\n",
            "Epoch 3/300\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 8.8621 - val_loss: 7.7123\n",
            "Epoch 4/300\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 6.5748 - val_loss: 6.0617\n",
            "Epoch 5/300\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 4.6233 - val_loss: 5.2833\n",
            "Epoch 6/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 4.3343 - val_loss: 5.0626\n",
            "Epoch 7/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 4.3169 - val_loss: 5.1755\n",
            "Epoch 8/300\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 4.3043 - val_loss: 5.1224\n",
            "Epoch 9/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 4.2942 - val_loss: 5.0694\n",
            "Epoch 10/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 4.2875 - val_loss: 5.1823\n",
            "Epoch 11/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 4.2829 - val_loss: 4.9616\n",
            "Epoch 12/300\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 4.2796 - val_loss: 5.0745\n",
            "Epoch 13/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 4.2599 - val_loss: 5.0214\n",
            "Epoch 14/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 4.2543 - val_loss: 5.1343\n",
            "Epoch 15/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 4.2477 - val_loss: 4.9136\n",
            "Epoch 16/300\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 4.2464 - val_loss: 5.0265\n",
            "Epoch 17/300\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 4.2257 - val_loss: 4.9735\n",
            "Epoch 18/300\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 4.2210 - val_loss: 5.0864\n",
            "Epoch 19/300\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 4.2125 - val_loss: 4.8657\n",
            "Epoch 20/300\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 4.2131 - val_loss: 4.9786\n",
            "Epoch 21/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 4.1918 - val_loss: 5.0915\n",
            "Epoch 22/300\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 4.1934 - val_loss: 4.8708\n",
            "Epoch 23/300\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 4.1839 - val_loss: 4.9837\n",
            "Epoch 24/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 4.1672 - val_loss: 4.9306\n",
            "Epoch 25/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 4.1586 - val_loss: 5.0435\n",
            "Epoch 26/300\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 4.1581 - val_loss: 4.8228\n",
            "Epoch 27/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 4.1507 - val_loss: 4.9357\n",
            "Epoch 28/300\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 4.1329 - val_loss: 4.8826\n",
            "Epoch 29/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 4.1253 - val_loss: 4.9955\n",
            "Epoch 30/300\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 4.1229 - val_loss: 4.7748\n",
            "Epoch 31/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 4.1175 - val_loss: 4.8877\n",
            "Epoch 32/300\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 4.0987 - val_loss: 4.8347\n",
            "Epoch 33/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 4.0921 - val_loss: 4.9476\n",
            "Epoch 34/300\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 4.0877 - val_loss: 4.7269\n",
            "Epoch 35/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 4.0842 - val_loss: 4.8398\n",
            "Epoch 36/300\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 4.0644 - val_loss: 4.7867\n",
            "Epoch 37/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 4.0589 - val_loss: 4.8996\n",
            "Epoch 38/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 4.0524 - val_loss: 4.6789\n",
            "Epoch 39/300\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 4.0510 - val_loss: 4.7918\n",
            "Epoch 40/300\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 4.0302 - val_loss: 4.7388\n",
            "Epoch 41/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 4.0256 - val_loss: 4.8517\n",
            "Epoch 42/300\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 4.0172 - val_loss: 4.6310\n",
            "Epoch 43/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 4.0177 - val_loss: 4.7439\n",
            "Epoch 44/300\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 3.9964 - val_loss: 4.8568\n",
            "Epoch 45/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 3.9981 - val_loss: 4.6361\n",
            "Epoch 46/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 3.9885 - val_loss: 4.7489\n",
            "Epoch 47/300\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 3.9717 - val_loss: 4.6959\n",
            "Epoch 48/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 3.9632 - val_loss: 4.8088\n",
            "Epoch 49/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 3.9629 - val_loss: 4.5881\n",
            "Epoch 50/300\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 3.9553 - val_loss: 4.7010\n",
            "Epoch 51/300\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 3.9374 - val_loss: 4.6479\n",
            "Epoch 52/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 3.9299 - val_loss: 4.7608\n",
            "Epoch 53/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 3.9276 - val_loss: 4.5401\n",
            "Epoch 54/300\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 3.9221 - val_loss: 4.6530\n",
            "Epoch 55/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 3.9032 - val_loss: 4.6000\n",
            "Epoch 56/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 3.8967 - val_loss: 4.7129\n",
            "Epoch 57/300\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 3.8924 - val_loss: 4.4922\n",
            "Epoch 58/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 3.8888 - val_loss: 4.6051\n",
            "Epoch 59/300\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 3.8689 - val_loss: 4.5520\n",
            "Epoch 60/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 3.8635 - val_loss: 4.6649\n",
            "Epoch 61/300\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 3.8572 - val_loss: 4.4442\n",
            "Epoch 62/300\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 3.8556 - val_loss: 4.5571\n",
            "Epoch 63/300\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 3.8347 - val_loss: 4.5041\n",
            "Epoch 64/300\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 3.8302 - val_loss: 4.6170\n",
            "Epoch 65/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 3.8219 - val_loss: 4.3963\n",
            "Epoch 66/300\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 3.8223 - val_loss: 4.5092\n",
            "Epoch 67/300\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 3.8010 - val_loss: 4.6220\n",
            "Epoch 68/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 3.8028 - val_loss: 4.4013\n",
            "Epoch 69/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 3.7931 - val_loss: 4.5142\n",
            "Epoch 70/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 3.7762 - val_loss: 4.4612\n",
            "Epoch 71/300\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 3.7678 - val_loss: 4.5741\n",
            "Epoch 72/300\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 3.7676 - val_loss: 4.3534\n",
            "Epoch 73/300\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 3.7599 - val_loss: 4.4663\n",
            "Epoch 74/300\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 3.7419 - val_loss: 4.4132\n",
            "Epoch 75/300\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 3.7345 - val_loss: 4.5261\n",
            "Epoch 76/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 3.7324 - val_loss: 4.3054\n",
            "Epoch 77/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 3.7267 - val_loss: 4.4183\n",
            "Epoch 78/300\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 3.7077 - val_loss: 4.3653\n",
            "Epoch 79/300\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 3.7013 - val_loss: 4.4782\n",
            "Epoch 80/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 3.6971 - val_loss: 4.2575\n",
            "Epoch 81/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 3.6934 - val_loss: 4.3704\n",
            "Epoch 82/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 3.6734 - val_loss: 4.3173\n",
            "Epoch 83/300\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 3.6681 - val_loss: 4.4302\n",
            "Epoch 84/300\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 3.6619 - val_loss: 4.2095\n",
            "Epoch 85/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 3.6602 - val_loss: 4.3224\n",
            "Epoch 86/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 3.6392 - val_loss: 4.2694\n",
            "Epoch 87/300\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 3.6348 - val_loss: 4.3823\n",
            "Epoch 88/300\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 3.6267 - val_loss: 4.1616\n",
            "Epoch 89/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 3.6269 - val_loss: 4.2744\n",
            "Epoch 90/300\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 3.6056 - val_loss: 4.3873\n",
            "Epoch 91/300\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 3.6076 - val_loss: 4.1666\n",
            "Epoch 92/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 3.5977 - val_loss: 4.2795\n",
            "Epoch 93/300\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 3.5807 - val_loss: 4.2265\n",
            "Epoch 94/300\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 3.5724 - val_loss: 4.3394\n",
            "Epoch 95/300\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 3.5723 - val_loss: 4.1187\n",
            "Epoch 96/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 3.5645 - val_loss: 4.2316\n",
            "Epoch 97/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 3.5464 - val_loss: 4.1785\n",
            "Epoch 98/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 3.5392 - val_loss: 4.2914\n",
            "Epoch 99/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 3.5371 - val_loss: 4.0707\n",
            "Epoch 100/300\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 3.5313 - val_loss: 4.1836\n",
            "Epoch 101/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 3.5122 - val_loss: 4.1306\n",
            "Epoch 102/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 3.5059 - val_loss: 4.2435\n",
            "Epoch 103/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 3.5019 - val_loss: 4.0228\n",
            "Epoch 104/300\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 3.4980 - val_loss: 4.1357\n",
            "Epoch 105/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 3.4779 - val_loss: 4.0826\n",
            "Epoch 106/300\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 3.4727 - val_loss: 4.1955\n",
            "Epoch 107/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 3.4667 - val_loss: 3.9748\n",
            "Epoch 108/300\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 3.4648 - val_loss: 4.0877\n",
            "Epoch 109/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 3.4437 - val_loss: 4.0347\n",
            "Epoch 110/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 3.4394 - val_loss: 4.1475\n",
            "Epoch 111/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 3.4314 - val_loss: 3.9268\n",
            "Epoch 112/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 3.4315 - val_loss: 4.0397\n",
            "Epoch 113/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 3.4102 - val_loss: 4.1526\n",
            "Epoch 114/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 3.4123 - val_loss: 3.9319\n",
            "Epoch 115/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 3.4023 - val_loss: 4.0448\n",
            "Epoch 116/300\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 3.3852 - val_loss: 3.9918\n",
            "Epoch 117/300\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 3.3770 - val_loss: 4.1047\n",
            "Epoch 118/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 3.3771 - val_loss: 3.8840\n",
            "Epoch 119/300\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 3.3691 - val_loss: 3.9969\n",
            "Epoch 120/300\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 3.3509 - val_loss: 3.9438\n",
            "Epoch 121/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 3.3438 - val_loss: 4.0567\n",
            "Epoch 122/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 3.3419 - val_loss: 3.8360\n",
            "Epoch 123/300\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 3.3359 - val_loss: 3.9489\n",
            "Epoch 124/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 3.3167 - val_loss: 3.8959\n",
            "Epoch 125/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 3.3105 - val_loss: 4.0088\n",
            "Epoch 126/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 3.3066 - val_loss: 3.7881\n",
            "Epoch 127/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 3.3026 - val_loss: 3.9010\n",
            "Epoch 128/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 3.2824 - val_loss: 3.8479\n",
            "Epoch 129/300\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 3.2773 - val_loss: 3.9608\n",
            "Epoch 130/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 3.2714 - val_loss: 3.7401\n",
            "Epoch 131/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 3.2694 - val_loss: 3.8530\n",
            "Epoch 132/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 3.2482 - val_loss: 3.7999\n",
            "Epoch 133/300\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 3.2440 - val_loss: 3.9128\n",
            "Epoch 134/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 3.2362 - val_loss: 3.6921\n",
            "Epoch 135/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 3.2361 - val_loss: 3.8050\n",
            "Epoch 136/300\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 3.2148 - val_loss: 3.9179\n",
            "Epoch 137/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 3.2171 - val_loss: 3.6972\n",
            "Epoch 138/300\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 3.2070 - val_loss: 3.8101\n",
            "Epoch 139/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 3.1897 - val_loss: 3.7571\n",
            "Epoch 140/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 3.1816 - val_loss: 3.8700\n",
            "Epoch 141/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 3.1818 - val_loss: 3.6493\n",
            "Epoch 142/300\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 3.1737 - val_loss: 3.7622\n",
            "Epoch 143/300\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 3.1554 - val_loss: 3.7091\n",
            "Epoch 144/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 3.1484 - val_loss: 3.8220\n",
            "Epoch 145/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 3.1466 - val_loss: 3.6013\n",
            "Epoch 146/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 3.1405 - val_loss: 3.7142\n",
            "Epoch 147/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 3.1212 - val_loss: 3.6612\n",
            "Epoch 148/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 3.1151 - val_loss: 3.7741\n",
            "Epoch 149/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 3.1114 - val_loss: 3.5534\n",
            "Epoch 150/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 3.1072 - val_loss: 3.6663\n",
            "Epoch 151/300\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 3.0869 - val_loss: 3.6132\n",
            "Epoch 152/300\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3.0819 - val_loss: 3.7261\n",
            "Epoch 153/300\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 3.0761 - val_loss: 3.5054\n",
            "Epoch 154/300\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 3.0740 - val_loss: 3.6183\n",
            "Epoch 155/300\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 3.0527 - val_loss: 3.7312\n",
            "Epoch 156/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 3.0570 - val_loss: 3.5105\n",
            "Epoch 157/300\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 3.0448 - val_loss: 3.6234\n",
            "Epoch 158/300\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 3.0284 - val_loss: 3.5703\n",
            "Epoch 159/300\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 3.0194 - val_loss: 3.6832\n",
            "Epoch 160/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 3.0218 - val_loss: 3.4625\n",
            "Epoch 161/300\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 3.0116 - val_loss: 3.5754\n",
            "Epoch 162/300\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.9942 - val_loss: 3.5224\n",
            "Epoch 163/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.9862 - val_loss: 3.6353\n",
            "Epoch 164/300\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.9866 - val_loss: 3.4146\n",
            "Epoch 165/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.9783 - val_loss: 3.5275\n",
            "Epoch 166/300\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.9599 - val_loss: 3.4744\n",
            "Epoch 167/300\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 2.9530 - val_loss: 3.5873\n",
            "Epoch 168/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.9513 - val_loss: 3.3666\n",
            "Epoch 169/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.9451 - val_loss: 3.4795\n",
            "Epoch 170/300\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.9257 - val_loss: 3.4265\n",
            "Epoch 171/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.9197 - val_loss: 3.5394\n",
            "Epoch 172/300\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 2.9161 - val_loss: 3.3187\n",
            "Epoch 173/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.9118 - val_loss: 3.4315\n",
            "Epoch 174/300\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 2.8914 - val_loss: 3.3785\n",
            "Epoch 175/300\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 2.8865 - val_loss: 3.4914\n",
            "Epoch 176/300\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.8809 - val_loss: 3.2707\n",
            "Epoch 177/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.8786 - val_loss: 3.3836\n",
            "Epoch 178/300\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2.8573 - val_loss: 3.4965\n",
            "Epoch 179/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.8618 - val_loss: 3.2758\n",
            "Epoch 180/300\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.8494 - val_loss: 3.3887\n",
            "Epoch 181/300\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.8329 - val_loss: 3.3356\n",
            "Epoch 182/300\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.8240 - val_loss: 3.4485\n",
            "Epoch 183/300\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.8265 - val_loss: 3.2278\n",
            "Epoch 184/300\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.8162 - val_loss: 3.3407\n",
            "Epoch 185/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.7987 - val_loss: 3.2877\n",
            "Epoch 186/300\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 2.7908 - val_loss: 3.4006\n",
            "Epoch 187/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.7913 - val_loss: 3.1799\n",
            "Epoch 188/300\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 2.7829 - val_loss: 3.2928\n",
            "Epoch 189/300\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.7644 - val_loss: 3.2397\n",
            "Epoch 190/300\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 2.7576 - val_loss: 3.3526\n",
            "Epoch 191/300\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 2.7561 - val_loss: 3.1319\n",
            "Epoch 192/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.7497 - val_loss: 3.2448\n",
            "Epoch 193/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.7302 - val_loss: 3.1918\n",
            "Epoch 194/300\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 2.7243 - val_loss: 3.3046\n",
            "Epoch 195/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.7209 - val_loss: 3.0839\n",
            "Epoch 196/300\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 2.7164 - val_loss: 3.1968\n",
            "Epoch 197/300\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 2.6959 - val_loss: 3.1438\n",
            "Epoch 198/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.6911 - val_loss: 3.2567\n",
            "Epoch 199/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.6856 - val_loss: 3.0360\n",
            "Epoch 200/300\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.6832 - val_loss: 3.1489\n",
            "Epoch 201/300\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.6619 - val_loss: 3.2618\n",
            "Epoch 202/300\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.6665 - val_loss: 3.0411\n",
            "Epoch 203/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.6540 - val_loss: 3.1540\n",
            "Epoch 204/300\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.6374 - val_loss: 3.1009\n",
            "Epoch 205/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.6287 - val_loss: 3.2138\n",
            "Epoch 206/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.6313 - val_loss: 2.9931\n",
            "Epoch 207/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.6208 - val_loss: 3.1060\n",
            "Epoch 208/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.6032 - val_loss: 3.0530\n",
            "Epoch 209/300\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.5954 - val_loss: 3.1659\n",
            "Epoch 210/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.5961 - val_loss: 2.9452\n",
            "Epoch 211/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.5875 - val_loss: 3.0581\n",
            "Epoch 212/300\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.5689 - val_loss: 3.0050\n",
            "Epoch 213/300\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.5622 - val_loss: 3.1179\n",
            "Epoch 214/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.5608 - val_loss: 2.8972\n",
            "Epoch 215/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.5543 - val_loss: 3.0101\n",
            "Epoch 216/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.5347 - val_loss: 2.9570\n",
            "Epoch 217/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.5289 - val_loss: 3.0699\n",
            "Epoch 218/300\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.5256 - val_loss: 2.8492\n",
            "Epoch 219/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.5210 - val_loss: 2.9621\n",
            "Epoch 220/300\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.5004 - val_loss: 2.9091\n",
            "Epoch 221/300\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.4957 - val_loss: 3.0220\n",
            "Epoch 222/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.4904 - val_loss: 2.8013\n",
            "Epoch 223/300\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 2.4878 - val_loss: 2.9142\n",
            "Epoch 224/300\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 2.4665 - val_loss: 3.0271\n",
            "Epoch 225/300\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 2.4713 - val_loss: 2.8064\n",
            "Epoch 226/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.4586 - val_loss: 2.9193\n",
            "Epoch 227/300\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.4419 - val_loss: 2.8662\n",
            "Epoch 228/300\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.4333 - val_loss: 2.9791\n",
            "Epoch 229/300\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 2.4360 - val_loss: 2.7584\n",
            "Epoch 230/300\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 2.4254 - val_loss: 2.8713\n",
            "Epoch 231/300\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.4077 - val_loss: 2.8183\n",
            "Epoch 232/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.4000 - val_loss: 2.9312\n",
            "Epoch 233/300\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.4008 - val_loss: 2.7105\n",
            "Epoch 234/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.3921 - val_loss: 2.8234\n",
            "Epoch 235/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.3734 - val_loss: 2.7703\n",
            "Epoch 236/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.3668 - val_loss: 2.8832\n",
            "Epoch 237/300\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 2.3656 - val_loss: 2.6625\n",
            "Epoch 238/300\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 2.3589 - val_loss: 2.7754\n",
            "Epoch 239/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.3391 - val_loss: 2.7223\n",
            "Epoch 240/300\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.3335 - val_loss: 2.8352\n",
            "Epoch 241/300\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 2.3303 - val_loss: 2.6145\n",
            "Epoch 242/300\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 2.3256 - val_loss: 2.7274\n",
            "Epoch 243/300\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.3049 - val_loss: 2.6744\n",
            "Epoch 244/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.3003 - val_loss: 2.7873\n",
            "Epoch 245/300\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 2.2951 - val_loss: 2.5666\n",
            "Epoch 246/300\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 2.2924 - val_loss: 2.6795\n",
            "Epoch 247/300\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.2711 - val_loss: 2.7924\n",
            "Epoch 248/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.2760 - val_loss: 2.5717\n",
            "Epoch 249/300\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.2632 - val_loss: 2.6846\n",
            "Epoch 250/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.2464 - val_loss: 2.6315\n",
            "Epoch 251/300\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 2.2379 - val_loss: 2.7444\n",
            "Epoch 252/300\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 2.2408 - val_loss: 2.5237\n",
            "Epoch 253/300\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.2300 - val_loss: 2.6366\n",
            "Epoch 254/300\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 2.2122 - val_loss: 2.5836\n",
            "Epoch 255/300\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 2.2046 - val_loss: 2.6965\n",
            "Epoch 256/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.2055 - val_loss: 2.4758\n",
            "Epoch 257/300\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.1967 - val_loss: 2.5886\n",
            "Epoch 258/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.1779 - val_loss: 2.5356\n",
            "Epoch 259/300\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.1714 - val_loss: 2.6485\n",
            "Epoch 260/300\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 2.1703 - val_loss: 2.4278\n",
            "Epoch 261/300\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.1635 - val_loss: 2.5407\n",
            "Epoch 262/300\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 2.1436 - val_loss: 2.4876\n",
            "Epoch 263/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.1381 - val_loss: 2.6005\n",
            "Epoch 264/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.1351 - val_loss: 2.3808\n",
            "Epoch 265/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.1302 - val_loss: 2.4927\n",
            "Epoch 266/300\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 2.1094 - val_loss: 2.4397\n",
            "Epoch 267/300\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.1049 - val_loss: 2.5526\n",
            "Epoch 268/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.0998 - val_loss: 2.3380\n",
            "Epoch 269/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.0970 - val_loss: 2.4448\n",
            "Epoch 270/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.0757 - val_loss: 2.5577\n",
            "Epoch 271/300\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.0807 - val_loss: 2.3370\n",
            "Epoch 272/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.0678 - val_loss: 2.4499\n",
            "Epoch 273/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.0509 - val_loss: 2.3968\n",
            "Epoch 274/300\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.0425 - val_loss: 2.5097\n",
            "Epoch 275/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.0455 - val_loss: 2.2890\n",
            "Epoch 276/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.0346 - val_loss: 2.4019\n",
            "Epoch 277/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.0167 - val_loss: 2.3489\n",
            "Epoch 278/300\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 2.0092 - val_loss: 2.4618\n",
            "Epoch 279/300\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.0103 - val_loss: 2.2411\n",
            "Epoch 280/300\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.0013 - val_loss: 2.3539\n",
            "Epoch 281/300\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.9824 - val_loss: 2.3009\n",
            "Epoch 282/300\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 1.9760 - val_loss: 2.4138\n",
            "Epoch 283/300\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 1.9750 - val_loss: 2.1965\n",
            "Epoch 284/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 1.9681 - val_loss: 2.3060\n",
            "Epoch 285/300\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 1.9481 - val_loss: 2.2529\n",
            "Epoch 286/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 1.9427 - val_loss: 2.3658\n",
            "Epoch 287/300\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 1.9398 - val_loss: 2.1536\n",
            "Epoch 288/300\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 1.9349 - val_loss: 2.2580\n",
            "Epoch 289/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 1.9139 - val_loss: 2.2050\n",
            "Epoch 290/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 1.9095 - val_loss: 2.3179\n",
            "Epoch 291/300\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 1.9046 - val_loss: 2.1108\n",
            "Epoch 292/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 1.9016 - val_loss: 2.2101\n",
            "Epoch 293/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 1.8803 - val_loss: 2.3230\n",
            "Epoch 294/300\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 1.8855 - val_loss: 2.1023\n",
            "Epoch 295/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 1.8724 - val_loss: 2.2152\n",
            "Epoch 296/300\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 1.8554 - val_loss: 2.1621\n",
            "Epoch 297/300\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.8471 - val_loss: 2.2750\n",
            "Epoch 298/300\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 1.8502 - val_loss: 2.0550\n",
            "Epoch 299/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 1.8392 - val_loss: 2.1672\n",
            "Epoch 300/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 1.8212 - val_loss: 2.1142\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc5a6426650>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "uUIfU246IhQ1",
        "outputId": "5e8998e1-8144-4855-aa6a-86d302eb5911"
      },
      "source": [
        "y_pred = model.predict(valid_X)\n",
        "plt.scatter(valid_X, valid_y)\n",
        "plt.scatter(valid_X, y_pred, color='r')"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7fc5a647d8d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OyfqJcJVy5TF"
      },
      "source": [
        "- 300번을 반복했어나 아직 수렴하지 않아서 lr을 키움\n",
        "- lr = 0.085"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OXUIm7qgJ2BB",
        "outputId": "b7fef4e5-c458-4fa6-8b2a-1d6035459064"
      },
      "source": [
        "model = Sequential([\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "model.compile(loss = 'mae', optimizer=SGD(lr=0.085))\n",
        "\n",
        "model.fit(train_X,\n",
        "          train_y,\n",
        "          validation_data=(valid_X, valid_y),\n",
        "          epochs=300)\n"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "1/1 [==============================] - 0s 315ms/step - loss: 7.6298 - val_loss: 5.7037\n",
            "Epoch 2/300\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 4.4651 - val_loss: 5.0232\n",
            "Epoch 3/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 4.3813 - val_loss: 5.2151\n",
            "Epoch 4/300\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 4.3513 - val_loss: 5.1249\n",
            "Epoch 5/300\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 4.3382 - val_loss: 5.3168\n",
            "Epoch 6/300\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 4.3416 - val_loss: 4.9416\n",
            "Epoch 7/300\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 4.3248 - val_loss: 5.1335\n",
            "Epoch 8/300\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 4.2931 - val_loss: 5.0434\n",
            "Epoch 9/300\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 4.2817 - val_loss: 5.2353\n",
            "Epoch 10/300\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 4.2818 - val_loss: 4.8601\n",
            "Epoch 11/300\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 4.2683 - val_loss: 5.0520\n",
            "Epoch 12/300\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 4.2348 - val_loss: 4.9618\n",
            "Epoch 13/300\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 4.2252 - val_loss: 5.1538\n",
            "Epoch 14/300\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 4.2219 - val_loss: 4.7786\n",
            "Epoch 15/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 4.2118 - val_loss: 4.9705\n",
            "Epoch 16/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 4.1766 - val_loss: 4.8803\n",
            "Epoch 17/300\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 4.1687 - val_loss: 5.0722\n",
            "Epoch 18/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 4.1620 - val_loss: 4.6970\n",
            "Epoch 19/300\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 4.1553 - val_loss: 4.8890\n",
            "Epoch 20/300\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 4.1191 - val_loss: 5.0809\n",
            "Epoch 21/300\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 4.1295 - val_loss: 4.7057\n",
            "Epoch 22/300\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 4.1057 - val_loss: 4.8976\n",
            "Epoch 23/300\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 4.0772 - val_loss: 4.8074\n",
            "Epoch 24/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 4.0626 - val_loss: 4.9993\n",
            "Epoch 25/300\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 4.0696 - val_loss: 4.6242\n",
            "Epoch 26/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 4.0491 - val_loss: 4.8161\n",
            "Epoch 27/300\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 4.0190 - val_loss: 4.7259\n",
            "Epoch 28/300\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 4.0061 - val_loss: 4.9178\n",
            "Epoch 29/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 4.0097 - val_loss: 4.5426\n",
            "Epoch 30/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 3.9926 - val_loss: 4.7345\n",
            "Epoch 31/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 3.9607 - val_loss: 4.6444\n",
            "Epoch 32/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 3.9495 - val_loss: 4.8363\n",
            "Epoch 33/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 3.9498 - val_loss: 4.4611\n",
            "Epoch 34/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 3.9361 - val_loss: 4.6530\n",
            "Epoch 35/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 3.9025 - val_loss: 4.5628\n",
            "Epoch 36/300\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 3.8930 - val_loss: 4.7548\n",
            "Epoch 37/300\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 3.8899 - val_loss: 4.3796\n",
            "Epoch 38/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 3.8796 - val_loss: 4.5715\n",
            "Epoch 39/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 3.8442 - val_loss: 4.4813\n",
            "Epoch 40/300\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 3.8365 - val_loss: 4.6732\n",
            "Epoch 41/300\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 3.8300 - val_loss: 4.2980\n",
            "Epoch 42/300\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 3.8231 - val_loss: 4.4900\n",
            "Epoch 43/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 3.7869 - val_loss: 4.6819\n",
            "Epoch 44/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 3.7975 - val_loss: 4.3067\n",
            "Epoch 45/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 3.7735 - val_loss: 4.4986\n",
            "Epoch 46/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 3.7448 - val_loss: 4.4084\n",
            "Epoch 47/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 3.7304 - val_loss: 4.6003\n",
            "Epoch 48/300\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 3.7377 - val_loss: 4.2252\n",
            "Epoch 49/300\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 3.7170 - val_loss: 4.4171\n",
            "Epoch 50/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 3.6866 - val_loss: 4.3269\n",
            "Epoch 51/300\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 3.6739 - val_loss: 4.5188\n",
            "Epoch 52/300\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 3.6778 - val_loss: 4.1436\n",
            "Epoch 53/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 3.6605 - val_loss: 4.3355\n",
            "Epoch 54/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 3.6284 - val_loss: 4.2454\n",
            "Epoch 55/300\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 3.6174 - val_loss: 4.4373\n",
            "Epoch 56/300\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 3.6179 - val_loss: 4.0621\n",
            "Epoch 57/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 3.6040 - val_loss: 4.2540\n",
            "Epoch 58/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 3.5701 - val_loss: 4.1638\n",
            "Epoch 59/300\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 3.5609 - val_loss: 4.3558\n",
            "Epoch 60/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 3.5580 - val_loss: 3.9806\n",
            "Epoch 61/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 3.5475 - val_loss: 4.1725\n",
            "Epoch 62/300\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 3.5119 - val_loss: 4.0823\n",
            "Epoch 63/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 3.5044 - val_loss: 4.2742\n",
            "Epoch 64/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 3.4981 - val_loss: 3.9027\n",
            "Epoch 65/300\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 3.4909 - val_loss: 4.0910\n",
            "Epoch 66/300\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 3.4547 - val_loss: 4.2829\n",
            "Epoch 67/300\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 3.4656 - val_loss: 3.9077\n",
            "Epoch 68/300\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 3.4413 - val_loss: 4.0996\n",
            "Epoch 69/300\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 3.4125 - val_loss: 4.0094\n",
            "Epoch 70/300\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 3.3982 - val_loss: 4.2013\n",
            "Epoch 71/300\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 3.4057 - val_loss: 3.8262\n",
            "Epoch 72/300\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 3.3848 - val_loss: 4.0181\n",
            "Epoch 73/300\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 3.3542 - val_loss: 3.9279\n",
            "Epoch 74/300\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 3.3417 - val_loss: 4.1198\n",
            "Epoch 75/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 3.3458 - val_loss: 3.7446\n",
            "Epoch 76/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 3.3283 - val_loss: 3.9365\n",
            "Epoch 77/300\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 3.2960 - val_loss: 3.8464\n",
            "Epoch 78/300\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 3.2852 - val_loss: 4.0383\n",
            "Epoch 79/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 3.2859 - val_loss: 3.6631\n",
            "Epoch 80/300\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 3.2718 - val_loss: 3.8550\n",
            "Epoch 81/300\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 3.2378 - val_loss: 3.7648\n",
            "Epoch 82/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 3.2287 - val_loss: 3.9568\n",
            "Epoch 83/300\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 3.2260 - val_loss: 3.5893\n",
            "Epoch 84/300\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 3.2153 - val_loss: 3.7735\n",
            "Epoch 85/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 3.1795 - val_loss: 3.6833\n",
            "Epoch 86/300\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 3.1722 - val_loss: 3.8752\n",
            "Epoch 87/300\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 3.1662 - val_loss: 3.5164\n",
            "Epoch 88/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 3.1588 - val_loss: 3.6920\n",
            "Epoch 89/300\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 3.1225 - val_loss: 3.8839\n",
            "Epoch 90/300\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 3.1337 - val_loss: 3.5087\n",
            "Epoch 91/300\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 3.1091 - val_loss: 3.7006\n",
            "Epoch 92/300\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 3.0801 - val_loss: 3.6104\n",
            "Epoch 93/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 3.0660 - val_loss: 3.8023\n",
            "Epoch 94/300\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 3.0738 - val_loss: 3.4272\n",
            "Epoch 95/300\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 3.0526 - val_loss: 3.6191\n",
            "Epoch 96/300\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 3.0219 - val_loss: 3.5289\n",
            "Epoch 97/300\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 3.0095 - val_loss: 3.7208\n",
            "Epoch 98/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 3.0139 - val_loss: 3.3488\n",
            "Epoch 99/300\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 2.9961 - val_loss: 3.5375\n",
            "Epoch 100/300\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.9636 - val_loss: 3.4474\n",
            "Epoch 101/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.9530 - val_loss: 3.6393\n",
            "Epoch 102/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.9540 - val_loss: 3.2759\n",
            "Epoch 103/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.9396 - val_loss: 3.4560\n",
            "Epoch 104/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.9054 - val_loss: 3.3658\n",
            "Epoch 105/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.8965 - val_loss: 3.5578\n",
            "Epoch 106/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.8941 - val_loss: 3.2030\n",
            "Epoch 107/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.8831 - val_loss: 3.3745\n",
            "Epoch 108/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.8472 - val_loss: 3.2843\n",
            "Epoch 109/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.8400 - val_loss: 3.4762\n",
            "Epoch 110/300\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 2.8342 - val_loss: 3.1302\n",
            "Epoch 111/300\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.8266 - val_loss: 3.2930\n",
            "Epoch 112/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.7904 - val_loss: 3.4849\n",
            "Epoch 113/300\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 2.8017 - val_loss: 3.1097\n",
            "Epoch 114/300\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 2.7770 - val_loss: 3.3016\n",
            "Epoch 115/300\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.7478 - val_loss: 3.2114\n",
            "Epoch 116/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.7339 - val_loss: 3.4033\n",
            "Epoch 117/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.7418 - val_loss: 3.0354\n",
            "Epoch 118/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.7205 - val_loss: 3.2201\n",
            "Epoch 119/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.6895 - val_loss: 3.1299\n",
            "Epoch 120/300\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.6774 - val_loss: 3.3218\n",
            "Epoch 121/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.6819 - val_loss: 2.9625\n",
            "Epoch 122/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.6639 - val_loss: 3.1385\n",
            "Epoch 123/300\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.6313 - val_loss: 3.0484\n",
            "Epoch 124/300\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.6209 - val_loss: 3.2403\n",
            "Epoch 125/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.6221 - val_loss: 2.8896\n",
            "Epoch 126/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.6074 - val_loss: 3.0570\n",
            "Epoch 127/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.5730 - val_loss: 2.9668\n",
            "Epoch 128/300\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.5643 - val_loss: 3.1588\n",
            "Epoch 129/300\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.5622 - val_loss: 2.8168\n",
            "Epoch 130/300\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 2.5509 - val_loss: 2.9755\n",
            "Epoch 131/300\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.5148 - val_loss: 2.8853\n",
            "Epoch 132/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.5078 - val_loss: 3.0772\n",
            "Epoch 133/300\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.5023 - val_loss: 2.7439\n",
            "Epoch 134/300\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.4944 - val_loss: 2.8940\n",
            "Epoch 135/300\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.4582 - val_loss: 3.0859\n",
            "Epoch 136/300\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 2.4698 - val_loss: 2.7220\n",
            "Epoch 137/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.4448 - val_loss: 2.9026\n",
            "Epoch 138/300\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.4154 - val_loss: 2.8124\n",
            "Epoch 139/300\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 2.4017 - val_loss: 3.0043\n",
            "Epoch 140/300\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 2.4099 - val_loss: 2.6491\n",
            "Epoch 141/300\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.3883 - val_loss: 2.8211\n",
            "Epoch 142/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.3572 - val_loss: 2.7309\n",
            "Epoch 143/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.3452 - val_loss: 2.9228\n",
            "Epoch 144/300\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.3500 - val_loss: 2.5763\n",
            "Epoch 145/300\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.3318 - val_loss: 2.7395\n",
            "Epoch 146/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.2989 - val_loss: 2.6494\n",
            "Epoch 147/300\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.2887 - val_loss: 2.8413\n",
            "Epoch 148/300\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.2901 - val_loss: 2.5034\n",
            "Epoch 149/300\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 2.2753 - val_loss: 2.6580\n",
            "Epoch 150/300\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.2407 - val_loss: 2.5678\n",
            "Epoch 151/300\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 2.2322 - val_loss: 2.7597\n",
            "Epoch 152/300\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 2.2302 - val_loss: 2.4305\n",
            "Epoch 153/300\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.2188 - val_loss: 2.5765\n",
            "Epoch 154/300\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 2.1825 - val_loss: 2.7684\n",
            "Epoch 155/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.1977 - val_loss: 2.4086\n",
            "Epoch 156/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.1691 - val_loss: 2.5851\n",
            "Epoch 157/300\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 2.1424 - val_loss: 2.3054\n",
            "Epoch 158/300\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.1619 - val_loss: 2.6607\n",
            "Epoch 159/300\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 2.1334 - val_loss: 2.3236\n",
            "Epoch 160/300\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 2.1156 - val_loss: 2.4774\n",
            "Epoch 161/300\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.0823 - val_loss: 2.3873\n",
            "Epoch 162/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.0725 - val_loss: 2.5792\n",
            "Epoch 163/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.0735 - val_loss: 2.2508\n",
            "Epoch 164/300\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.0591 - val_loss: 2.3959\n",
            "Epoch 165/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.0241 - val_loss: 2.3057\n",
            "Epoch 166/300\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.0160 - val_loss: 2.4977\n",
            "Epoch 167/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.0136 - val_loss: 2.1779\n",
            "Epoch 168/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.0026 - val_loss: 2.3144\n",
            "Epoch 169/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 1.9664 - val_loss: 2.5063\n",
            "Epoch 170/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 1.9812 - val_loss: 2.0131\n",
            "Epoch 171/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.0163 - val_loss: 2.5209\n",
            "Epoch 172/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 1.9694 - val_loss: 2.0031\n",
            "Epoch 173/300\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 1.9755 - val_loss: 2.2911\n",
            "Epoch 174/300\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 1.8984 - val_loss: 2.0212\n",
            "Epoch 175/300\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 1.9216 - val_loss: 2.3667\n",
            "Epoch 176/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 1.8893 - val_loss: 2.0394\n",
            "Epoch 177/300\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 1.8716 - val_loss: 2.1834\n",
            "Epoch 178/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 1.8381 - val_loss: 2.0933\n",
            "Epoch 179/300\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 1.8285 - val_loss: 2.2852\n",
            "Epoch 180/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 1.8294 - val_loss: 1.9665\n",
            "Epoch 181/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 1.8151 - val_loss: 2.1019\n",
            "Epoch 182/300\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 1.7798 - val_loss: 2.0117\n",
            "Epoch 183/300\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 1.7720 - val_loss: 2.2036\n",
            "Epoch 184/300\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.7695 - val_loss: 1.8937\n",
            "Epoch 185/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 1.7597 - val_loss: 2.2792\n",
            "Epoch 186/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 1.7744 - val_loss: 1.6236\n",
            "Epoch 187/300\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.9221 - val_loss: 2.2183\n",
            "Epoch 188/300\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 1.7348 - val_loss: 1.7240\n",
            "Epoch 189/300\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 1.7628 - val_loss: 2.4685\n",
            "Epoch 190/300\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 1.8867 - val_loss: 1.3652\n",
            "Epoch 191/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.1409 - val_loss: 2.1518\n",
            "Epoch 192/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 1.6818 - val_loss: 1.6612\n",
            "Epoch 193/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 1.7151 - val_loss: 2.4020\n",
            "Epoch 194/300\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 1.8365 - val_loss: 1.3023\n",
            "Epoch 195/300\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 2.0987 - val_loss: 2.0853\n",
            "Epoch 196/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 1.6290 - val_loss: 1.4529\n",
            "Epoch 197/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 1.8194 - val_loss: 2.2367\n",
            "Epoch 198/300\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 1.7054 - val_loss: 1.2007\n",
            "Epoch 199/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.1315 - val_loss: 2.0975\n",
            "Epoch 200/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 1.6153 - val_loss: 1.4280\n",
            "Epoch 201/300\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 1.7321 - val_loss: 2.0366\n",
            "Epoch 202/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 1.5752 - val_loss: 1.3830\n",
            "Epoch 203/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 1.7236 - val_loss: 2.1880\n",
            "Epoch 204/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 1.6719 - val_loss: 1.1346\n",
            "Epoch 205/300\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.0361 - val_loss: 2.0488\n",
            "Epoch 206/300\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 1.5652 - val_loss: 1.2032\n",
            "Epoch 207/300\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.8515 - val_loss: 2.0723\n",
            "Epoch 208/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 1.5812 - val_loss: 1.0832\n",
            "Epoch 209/300\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.0403 - val_loss: 1.9332\n",
            "Epoch 210/300\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 1.4862 - val_loss: 1.2740\n",
            "Epoch 211/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 1.6239 - val_loss: 2.0846\n",
            "Epoch 212/300\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1.5955 - val_loss: 1.0451\n",
            "Epoch 213/300\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.9447 - val_loss: 1.9454\n",
            "Epoch 214/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 1.4834 - val_loss: 1.0109\n",
            "Epoch 215/300\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 2.0102 - val_loss: 1.8062\n",
            "Epoch 216/300\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 1.3957 - val_loss: 1.1695\n",
            "Epoch 217/300\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 1.5842 - val_loss: 2.1613\n",
            "Epoch 218/300\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 1.7338 - val_loss: 1.1913\n",
            "Epoch 219/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.8170 - val_loss: 1.5635\n",
            "Epoch 220/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 1.2965 - val_loss: 1.3195\n",
            "Epoch 221/300\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 1.3305 - val_loss: 1.6391\n",
            "Epoch 222/300\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 1.2906 - val_loss: 1.1949\n",
            "Epoch 223/300\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 1.3922 - val_loss: 1.8893\n",
            "Epoch 224/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 1.4505 - val_loss: 0.9623\n",
            "Epoch 225/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.1743 - val_loss: 1.8262\n",
            "Epoch 226/300\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 1.3974 - val_loss: 0.8882\n",
            "Epoch 227/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 1.8680 - val_loss: 1.8413\n",
            "Epoch 228/300\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1.4175 - val_loss: 0.9359\n",
            "Epoch 229/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.1488 - val_loss: 1.7782\n",
            "Epoch 230/300\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 1.3616 - val_loss: 0.8571\n",
            "Epoch 231/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 1.8355 - val_loss: 1.7933\n",
            "Epoch 232/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 1.3844 - val_loss: 0.9094\n",
            "Epoch 233/300\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.1233 - val_loss: 1.7302\n",
            "Epoch 234/300\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.3282 - val_loss: 0.9056\n",
            "Epoch 235/300\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 2.1517 - val_loss: 1.6671\n",
            "Epoch 236/300\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 1.2757 - val_loss: 0.8268\n",
            "Epoch 237/300\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 1.8278 - val_loss: 1.8306\n",
            "Epoch 238/300\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 1.4817 - val_loss: 1.2460\n",
            "Epoch 239/300\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 2.8452 - val_loss: 1.3523\n",
            "Epoch 240/300\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 1.0885 - val_loss: 1.0904\n",
            "Epoch 241/300\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.1054 - val_loss: 1.4279\n",
            "Epoch 242/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 1.1018 - val_loss: 0.8203\n",
            "Epoch 243/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 1.3671 - val_loss: 1.7829\n",
            "Epoch 244/300\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 1.4803 - val_loss: 1.2375\n",
            "Epoch 245/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.7907 - val_loss: 1.3046\n",
            "Epoch 246/300\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 1.0291 - val_loss: 0.8843\n",
            "Epoch 247/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 1.1741 - val_loss: 1.9708\n",
            "Epoch 248/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 1.7791 - val_loss: 1.0876\n",
            "Epoch 249/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.5088 - val_loss: 1.4925\n",
            "Epoch 250/300\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.1474 - val_loss: 0.8855\n",
            "Epoch 251/300\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 2.1352 - val_loss: 1.7934\n",
            "Epoch 252/300\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 1.5600 - val_loss: 1.1897\n",
            "Epoch 253/300\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.6686 - val_loss: 1.4141\n",
            "Epoch 254/300\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1.0823 - val_loss: 0.7362\n",
            "Epoch 255/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 1.7810 - val_loss: 1.7144\n",
            "Epoch 256/300\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 1.4811 - val_loss: 1.2235\n",
            "Epoch 257/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.7137 - val_loss: 1.3351\n",
            "Epoch 258/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 1.0203 - val_loss: 0.7475\n",
            "Epoch 259/300\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 1.8089 - val_loss: 1.8801\n",
            "Epoch 260/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 1.7392 - val_loss: 1.0946\n",
            "Epoch 261/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.4680 - val_loss: 1.4017\n",
            "Epoch 262/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 1.0923 - val_loss: 1.1397\n",
            "Epoch 263/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.5419 - val_loss: 1.4208\n",
            "Epoch 264/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 1.1262 - val_loss: 1.4335\n",
            "Epoch 265/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.9898 - val_loss: 1.2251\n",
            "Epoch 266/300\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.9351 - val_loss: 0.6309\n",
            "Epoch 267/300\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 1.4879 - val_loss: 1.8656\n",
            "Epoch 268/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 1.7722 - val_loss: 1.0711\n",
            "Epoch 269/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.3987 - val_loss: 1.4864\n",
            "Epoch 270/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 1.2565 - val_loss: 1.3616\n",
            "Epoch 271/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.8461 - val_loss: 1.2906\n",
            "Epoch 272/300\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 1.0001 - val_loss: 1.1828\n",
            "Epoch 273/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.5790 - val_loss: 1.3097\n",
            "Epoch 274/300\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.0313 - val_loss: 1.5066\n",
            "Epoch 275/300\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 3.0449 - val_loss: 1.1140\n",
            "Epoch 276/300\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.8531 - val_loss: 0.6074\n",
            "Epoch 277/300\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 1.4908 - val_loss: 1.7545\n",
            "Epoch 278/300\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 1.6772 - val_loss: 1.1108\n",
            "Epoch 279/300\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 2.4357 - val_loss: 1.3752\n",
            "Epoch 280/300\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.1616 - val_loss: 1.4347\n",
            "Epoch 281/300\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.9012 - val_loss: 1.1795\n",
            "Epoch 282/300\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.9099 - val_loss: 0.9581\n",
            "Epoch 283/300\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.1546 - val_loss: 1.5795\n",
            "Epoch 284/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 1.4663 - val_loss: 1.2498\n",
            "Epoch 285/300\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.6048 - val_loss: 1.3837\n",
            "Epoch 286/300\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 1.2024 - val_loss: 1.4224\n",
            "Epoch 287/300\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 2.8467 - val_loss: 1.1880\n",
            "Epoch 288/300\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.9385 - val_loss: 1.6181\n",
            "Epoch 289/300\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 3.0886 - val_loss: 0.9923\n",
            "Epoch 290/300\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.7617 - val_loss: 0.4893\n",
            "Epoch 291/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 1.1493 - val_loss: 1.8276\n",
            "Epoch 292/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 1.8566 - val_loss: 1.0174\n",
            "Epoch 293/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.2201 - val_loss: 1.4483\n",
            "Epoch 294/300\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 1.3409 - val_loss: 1.3578\n",
            "Epoch 295/300\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 2.6899 - val_loss: 1.2526\n",
            "Epoch 296/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 1.0770 - val_loss: 1.5535\n",
            "Epoch 297/300\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 2.9317 - val_loss: 1.0568\n",
            "Epoch 298/300\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.8195 - val_loss: 1.3509\n",
            "Epoch 299/300\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 2.6555 - val_loss: 1.2595\n",
            "Epoch 300/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 1.1036 - val_loss: 1.5466\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc5a5aab050>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "mo9cYDoF1Oig",
        "outputId": "838fa486-367a-49b2-dd37-a0e3489dae0c"
      },
      "source": [
        "y_pred = model.predict(valid_X)\n",
        "plt.scatter(valid_X, valid_y)\n",
        "plt.scatter(valid_X, y_pred, color='r')"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7fc5a5a4ea50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JY0d3glC1gDl"
      },
      "source": [
        "- lr=0.05 -> lr=0.085로 변경\n",
        "- 과적합이 발생"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUfrxDWutrYZ"
      },
      "source": [
        "이번에는 SGD 대신 Adam으로 진행\n",
        "- lr = 0.05\n",
        "- epochs = 300 (SGD 초기 조건과 동일하게 시작)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fK6wTTujQz3I",
        "outputId": "cd6d8776-8186-4966-8345-a744633582bd"
      },
      "source": [
        "model = Sequential([\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "model.compile(loss = 'mae', optimizer=Adam(lr=0.05))\n",
        "\n",
        "model.fit(train_X,\n",
        "          train_y,\n",
        "          validation_data=(valid_X, valid_y),\n",
        "          epochs=300)\n"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "1/1 [==============================] - 0s 365ms/step - loss: 4.4916 - val_loss: 4.9179\n",
            "Epoch 2/300\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 4.4379 - val_loss: 5.0431\n",
            "Epoch 3/300\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 4.3949 - val_loss: 5.2098\n",
            "Epoch 4/300\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 4.3567 - val_loss: 5.3232\n",
            "Epoch 5/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 4.3527 - val_loss: 5.3266\n",
            "Epoch 6/300\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 4.3367 - val_loss: 5.2611\n",
            "Epoch 7/300\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 4.3088 - val_loss: 5.1487\n",
            "Epoch 8/300\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 4.2739 - val_loss: 5.0360\n",
            "Epoch 9/300\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 4.2527 - val_loss: 4.9638\n",
            "Epoch 10/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 4.2373 - val_loss: 4.9246\n",
            "Epoch 11/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 4.2184 - val_loss: 4.9130\n",
            "Epoch 12/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 4.1965 - val_loss: 4.9246\n",
            "Epoch 13/300\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 4.1721 - val_loss: 4.9559\n",
            "Epoch 14/300\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 4.1492 - val_loss: 4.9725\n",
            "Epoch 15/300\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 4.1299 - val_loss: 4.9759\n",
            "Epoch 16/300\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 4.1129 - val_loss: 4.9323\n",
            "Epoch 17/300\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 4.0889 - val_loss: 4.8503\n",
            "Epoch 18/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 4.0663 - val_loss: 4.7652\n",
            "Epoch 19/300\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 4.0494 - val_loss: 4.7090\n",
            "Epoch 20/300\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 4.0322 - val_loss: 4.6784\n",
            "Epoch 21/300\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 4.0123 - val_loss: 4.6702\n",
            "Epoch 22/300\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 3.9900 - val_loss: 4.6820\n",
            "Epoch 23/300\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 3.9656 - val_loss: 4.7114\n",
            "Epoch 24/300\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 3.9433 - val_loss: 4.7277\n",
            "Epoch 25/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 3.9242 - val_loss: 4.7319\n",
            "Epoch 26/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 3.9079 - val_loss: 4.6932\n",
            "Epoch 27/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 3.8848 - val_loss: 4.6179\n",
            "Epoch 28/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 3.8610 - val_loss: 4.5390\n",
            "Epoch 29/300\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 3.8414 - val_loss: 4.4870\n",
            "Epoch 30/300\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 3.8237 - val_loss: 4.4589\n",
            "Epoch 31/300\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 3.8035 - val_loss: 4.4523\n",
            "Epoch 32/300\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 3.7811 - val_loss: 4.4649\n",
            "Epoch 33/300\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 3.7571 - val_loss: 4.4660\n",
            "Epoch 34/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 3.7375 - val_loss: 4.4567\n",
            "Epoch 35/300\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 3.7174 - val_loss: 4.4377\n",
            "Epoch 36/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 3.6970 - val_loss: 4.4098\n",
            "Epoch 37/300\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 3.6763 - val_loss: 4.3739\n",
            "Epoch 38/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 3.6553 - val_loss: 4.3306\n",
            "Epoch 39/300\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 3.6340 - val_loss: 4.2805\n",
            "Epoch 40/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 3.6136 - val_loss: 4.2559\n",
            "Epoch 41/300\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 3.5930 - val_loss: 4.2541\n",
            "Epoch 42/300\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 3.5720 - val_loss: 4.2416\n",
            "Epoch 43/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 3.5518 - val_loss: 4.2194\n",
            "Epoch 44/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 3.5313 - val_loss: 4.1883\n",
            "Epoch 45/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 3.5104 - val_loss: 4.1490\n",
            "Epoch 46/300\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 3.4892 - val_loss: 4.1023\n",
            "Epoch 47/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 3.4697 - val_loss: 4.0819\n",
            "Epoch 48/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 3.4486 - val_loss: 4.0850\n",
            "Epoch 49/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 3.4277 - val_loss: 4.0766\n",
            "Epoch 50/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 3.4076 - val_loss: 4.0579\n",
            "Epoch 51/300\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 3.3872 - val_loss: 4.0296\n",
            "Epoch 52/300\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 3.3664 - val_loss: 3.9927\n",
            "Epoch 53/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 3.3453 - val_loss: 3.9478\n",
            "Epoch 54/300\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 3.3239 - val_loss: 3.8956\n",
            "Epoch 55/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 3.3054 - val_loss: 3.8715\n",
            "Epoch 56/300\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 3.2847 - val_loss: 3.8726\n",
            "Epoch 57/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 3.2619 - val_loss: 3.8621\n",
            "Epoch 58/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 3.2418 - val_loss: 3.8411\n",
            "Epoch 59/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 3.2212 - val_loss: 3.8104\n",
            "Epoch 60/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 3.2003 - val_loss: 3.7709\n",
            "Epoch 61/300\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 3.1791 - val_loss: 3.7235\n",
            "Epoch 62/300\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 3.1607 - val_loss: 3.7046\n",
            "Epoch 63/300\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 3.1394 - val_loss: 3.7112\n",
            "Epoch 64/300\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 3.1177 - val_loss: 3.7055\n",
            "Epoch 65/300\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 3.0977 - val_loss: 3.6885\n",
            "Epoch 66/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 3.0773 - val_loss: 3.6613\n",
            "Epoch 67/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 3.0565 - val_loss: 3.6248\n",
            "Epoch 68/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 3.0354 - val_loss: 3.5797\n",
            "Epoch 69/300\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 3.0140 - val_loss: 3.5269\n",
            "Epoch 70/300\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 2.9952 - val_loss: 3.5043\n",
            "Epoch 71/300\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.9743 - val_loss: 3.5085\n",
            "Epoch 72/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.9521 - val_loss: 3.5004\n",
            "Epoch 73/300\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 2.9320 - val_loss: 3.4810\n",
            "Epoch 74/300\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 2.9115 - val_loss: 3.4513\n",
            "Epoch 75/300\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 2.8907 - val_loss: 3.4123\n",
            "Epoch 76/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.8695 - val_loss: 3.3648\n",
            "Epoch 77/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.8493 - val_loss: 3.3475\n",
            "Epoch 78/300\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 2.8278 - val_loss: 3.3574\n",
            "Epoch 79/300\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 2.8081 - val_loss: 3.3541\n",
            "Epoch 80/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.7882 - val_loss: 3.3389\n",
            "Epoch 81/300\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.7685 - val_loss: 3.2743\n",
            "Epoch 82/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.7458 - val_loss: 3.2036\n",
            "Epoch 83/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.7265 - val_loss: 3.1655\n",
            "Epoch 84/300\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.7073 - val_loss: 3.1564\n",
            "Epoch 85/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.6850 - val_loss: 3.1733\n",
            "Epoch 86/300\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.6630 - val_loss: 3.1765\n",
            "Epoch 87/300\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.6434 - val_loss: 3.1671\n",
            "Epoch 88/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.6243 - val_loss: 3.1081\n",
            "Epoch 89/300\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 2.6014 - val_loss: 3.0426\n",
            "Epoch 90/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.5806 - val_loss: 3.0088\n",
            "Epoch 91/300\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.5609 - val_loss: 3.0034\n",
            "Epoch 92/300\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 2.5383 - val_loss: 2.9865\n",
            "Epoch 93/300\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 2.5179 - val_loss: 2.9589\n",
            "Epoch 94/300\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 2.4971 - val_loss: 2.9219\n",
            "Epoch 95/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.4770 - val_loss: 2.9139\n",
            "Epoch 96/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.4560 - val_loss: 2.8944\n",
            "Epoch 97/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.4355 - val_loss: 2.8646\n",
            "Epoch 98/300\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 2.4147 - val_loss: 2.8253\n",
            "Epoch 99/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.3941 - val_loss: 2.8157\n",
            "Epoch 100/300\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 2.3733 - val_loss: 2.7947\n",
            "Epoch 101/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.3528 - val_loss: 2.7634\n",
            "Epoch 102/300\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.3319 - val_loss: 2.7227\n",
            "Epoch 103/300\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.3118 - val_loss: 2.7121\n",
            "Epoch 104/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.2905 - val_loss: 2.6902\n",
            "Epoch 105/300\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.2699 - val_loss: 2.6579\n",
            "Epoch 106/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.2490 - val_loss: 2.6163\n",
            "Epoch 107/300\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 2.2299 - val_loss: 2.6052\n",
            "Epoch 108/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.2078 - val_loss: 2.6215\n",
            "Epoch 109/300\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.1883 - val_loss: 2.6237\n",
            "Epoch 110/300\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 2.1706 - val_loss: 2.5736\n",
            "Epoch 111/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.1470 - val_loss: 2.5158\n",
            "Epoch 112/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.1252 - val_loss: 2.4512\n",
            "Epoch 113/300\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.1076 - val_loss: 2.4193\n",
            "Epoch 114/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.0877 - val_loss: 2.4168\n",
            "Epoch 115/300\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.0648 - val_loss: 2.4404\n",
            "Epoch 116/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.0434 - val_loss: 2.4494\n",
            "Epoch 117/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.0260 - val_loss: 2.4056\n",
            "Epoch 118/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.0026 - val_loss: 2.3537\n",
            "Epoch 119/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 1.9810 - val_loss: 2.2944\n",
            "Epoch 120/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 1.9613 - val_loss: 2.2671\n",
            "Epoch 121/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 1.9409 - val_loss: 2.2683\n",
            "Epoch 122/300\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1.9186 - val_loss: 2.2571\n",
            "Epoch 123/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 1.8984 - val_loss: 2.2346\n",
            "Epoch 124/300\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.8778 - val_loss: 2.2017\n",
            "Epoch 125/300\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1.8569 - val_loss: 2.1596\n",
            "Epoch 126/300\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 1.8360 - val_loss: 2.1480\n",
            "Epoch 127/300\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 1.8154 - val_loss: 2.1251\n",
            "Epoch 128/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 1.7948 - val_loss: 2.0918\n",
            "Epoch 129/300\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 1.7739 - val_loss: 2.0493\n",
            "Epoch 130/300\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 1.7545 - val_loss: 2.0375\n",
            "Epoch 131/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 1.7325 - val_loss: 2.0534\n",
            "Epoch 132/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 1.7131 - val_loss: 2.0552\n",
            "Epoch 133/300\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.6963 - val_loss: 2.0044\n",
            "Epoch 134/300\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.6718 - val_loss: 1.9460\n",
            "Epoch 135/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 1.6500 - val_loss: 1.8808\n",
            "Epoch 136/300\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 1.6327 - val_loss: 1.8486\n",
            "Epoch 137/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 1.6128 - val_loss: 1.8459\n",
            "Epoch 138/300\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.5898 - val_loss: 1.8697\n",
            "Epoch 139/300\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 1.5682 - val_loss: 1.8786\n",
            "Epoch 140/300\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 1.5513 - val_loss: 1.8346\n",
            "Epoch 141/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 1.5274 - val_loss: 1.7824\n",
            "Epoch 142/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 1.5057 - val_loss: 1.7228\n",
            "Epoch 143/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 1.4865 - val_loss: 1.6954\n",
            "Epoch 144/300\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.4661 - val_loss: 1.6968\n",
            "Epoch 145/300\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 1.4434 - val_loss: 1.6857\n",
            "Epoch 146/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 1.4232 - val_loss: 1.6631\n",
            "Epoch 147/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 1.4026 - val_loss: 1.6303\n",
            "Epoch 148/300\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 1.3817 - val_loss: 1.5881\n",
            "Epoch 149/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 1.3612 - val_loss: 1.5765\n",
            "Epoch 150/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 1.3402 - val_loss: 1.5536\n",
            "Epoch 151/300\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 1.3196 - val_loss: 1.5203\n",
            "Epoch 152/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 1.2987 - val_loss: 1.4777\n",
            "Epoch 153/300\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 1.2798 - val_loss: 1.4660\n",
            "Epoch 154/300\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 1.2578 - val_loss: 1.4820\n",
            "Epoch 155/300\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 1.2380 - val_loss: 1.4839\n",
            "Epoch 156/300\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 1.2216 - val_loss: 1.4331\n",
            "Epoch 157/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 1.1967 - val_loss: 1.3747\n",
            "Epoch 158/300\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 1.1748 - val_loss: 1.3094\n",
            "Epoch 159/300\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 1.1579 - val_loss: 1.2772\n",
            "Epoch 160/300\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 1.1381 - val_loss: 1.2747\n",
            "Epoch 161/300\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 1.1151 - val_loss: 1.2987\n",
            "Epoch 162/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 1.0931 - val_loss: 1.3079\n",
            "Epoch 163/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 1.0768 - val_loss: 1.2639\n",
            "Epoch 164/300\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 1.0527 - val_loss: 1.1728\n",
            "Epoch 165/300\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 1.0328 - val_loss: 1.1244\n",
            "Epoch 166/300\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 1.0155 - val_loss: 1.1005\n",
            "Epoch 167/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.9948 - val_loss: 1.0960\n",
            "Epoch 168/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.9712 - val_loss: 1.1249\n",
            "Epoch 169/300\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.9486 - val_loss: 1.1386\n",
            "Epoch 170/300\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.9332 - val_loss: 1.0997\n",
            "Epoch 171/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.9101 - val_loss: 1.0141\n",
            "Epoch 172/300\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.8869 - val_loss: 0.9654\n",
            "Epoch 173/300\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.8691 - val_loss: 0.9431\n",
            "Epoch 174/300\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.8481 - val_loss: 0.9472\n",
            "Epoch 175/300\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.8243 - val_loss: 0.9777\n",
            "Epoch 176/300\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.8074 - val_loss: 0.9547\n",
            "Epoch 177/300\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.7872 - val_loss: 0.8843\n",
            "Epoch 178/300\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.7623 - val_loss: 0.8192\n",
            "Epoch 179/300\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.7460 - val_loss: 0.7866\n",
            "Epoch 180/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.7273 - val_loss: 0.7675\n",
            "Epoch 181/300\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.7056 - val_loss: 0.7630\n",
            "Epoch 182/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.6812 - val_loss: 0.7982\n",
            "Epoch 183/300\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.6622 - val_loss: 0.7802\n",
            "Epoch 184/300\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6428 - val_loss: 0.7150\n",
            "Epoch 185/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.6181 - val_loss: 0.6556\n",
            "Epoch 186/300\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.6009 - val_loss: 0.6247\n",
            "Epoch 187/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.5818 - val_loss: 0.6071\n",
            "Epoch 188/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.5598 - val_loss: 0.6076\n",
            "Epoch 189/300\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5354 - val_loss: 0.6082\n",
            "Epoch 190/300\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5157 - val_loss: 0.5968\n",
            "Epoch 191/300\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.4969 - val_loss: 0.5375\n",
            "Epoch 192/300\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.4737 - val_loss: 0.4884\n",
            "Epoch 193/300\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.4566 - val_loss: 0.4598\n",
            "Epoch 194/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.4370 - val_loss: 0.4442\n",
            "Epoch 195/300\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.4146 - val_loss: 0.4482\n",
            "Epoch 196/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.3917 - val_loss: 0.4523\n",
            "Epoch 197/300\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.3741 - val_loss: 0.4071\n",
            "Epoch 198/300\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.3508 - val_loss: 0.3591\n",
            "Epoch 199/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.3298 - val_loss: 0.3358\n",
            "Epoch 200/300\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.3091 - val_loss: 0.3340\n",
            "Epoch 201/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.2890 - val_loss: 0.3247\n",
            "Epoch 202/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.2706 - val_loss: 0.2691\n",
            "Epoch 203/300\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.2472 - val_loss: 0.2271\n",
            "Epoch 204/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.2296 - val_loss: 0.1993\n",
            "Epoch 205/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.2107 - val_loss: 0.1993\n",
            "Epoch 206/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.1855 - val_loss: 0.2097\n",
            "Epoch 207/300\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.1712 - val_loss: 0.1537\n",
            "Epoch 208/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.1444 - val_loss: 0.1340\n",
            "Epoch 209/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.1283 - val_loss: 0.1278\n",
            "Epoch 210/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.1106 - val_loss: 0.1460\n",
            "Epoch 211/300\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0996 - val_loss: 0.1200\n",
            "Epoch 212/300\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0963 - val_loss: 0.1362\n",
            "Epoch 213/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0884 - val_loss: 0.1236\n",
            "Epoch 214/300\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0862 - val_loss: 0.1375\n",
            "Epoch 215/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0868 - val_loss: 0.1330\n",
            "Epoch 216/300\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0854 - val_loss: 0.1296\n",
            "Epoch 217/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0901 - val_loss: 0.1450\n",
            "Epoch 218/300\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0960 - val_loss: 0.1350\n",
            "Epoch 219/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0953 - val_loss: 0.1338\n",
            "Epoch 220/300\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0985 - val_loss: 0.1443\n",
            "Epoch 221/300\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.1020 - val_loss: 0.1347\n",
            "Epoch 222/300\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.1027 - val_loss: 0.1361\n",
            "Epoch 223/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.1029 - val_loss: 0.1495\n",
            "Epoch 224/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.1070 - val_loss: 0.1420\n",
            "Epoch 225/300\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.1028 - val_loss: 0.1349\n",
            "Epoch 226/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.1028 - val_loss: 0.1489\n",
            "Epoch 227/300\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.1047 - val_loss: 0.1439\n",
            "Epoch 228/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.1003 - val_loss: 0.1369\n",
            "Epoch 229/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.1136 - val_loss: 0.1603\n",
            "Epoch 230/300\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.1241 - val_loss: 0.1317\n",
            "Epoch 231/300\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0948 - val_loss: 0.1314\n",
            "Epoch 232/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0948 - val_loss: 0.1575\n",
            "Epoch 233/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.1172 - val_loss: 0.1284\n",
            "Epoch 234/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0876 - val_loss: 0.1326\n",
            "Epoch 235/300\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.1080 - val_loss: 0.1418\n",
            "Epoch 236/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0909 - val_loss: 0.1467\n",
            "Epoch 237/300\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0964 - val_loss: 0.1243\n",
            "Epoch 238/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0834 - val_loss: 0.1250\n",
            "Epoch 239/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0875 - val_loss: 0.1361\n",
            "Epoch 240/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0874 - val_loss: 0.1393\n",
            "Epoch 241/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0900 - val_loss: 0.1251\n",
            "Epoch 242/300\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0949 - val_loss: 0.1230\n",
            "Epoch 243/300\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0898 - val_loss: 0.1405\n",
            "Epoch 244/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0909 - val_loss: 0.1403\n",
            "Epoch 245/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0909 - val_loss: 0.1217\n",
            "Epoch 246/300\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0892 - val_loss: 0.1218\n",
            "Epoch 247/300\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0899 - val_loss: 0.1342\n",
            "Epoch 248/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0872 - val_loss: 0.1397\n",
            "Epoch 249/300\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0907 - val_loss: 0.1216\n",
            "Epoch 250/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0895 - val_loss: 0.1220\n",
            "Epoch 251/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0900 - val_loss: 0.1329\n",
            "Epoch 252/300\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0864 - val_loss: 0.1380\n",
            "Epoch 253/300\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0894 - val_loss: 0.1214\n",
            "Epoch 254/300\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0864 - val_loss: 0.1210\n",
            "Epoch 255/300\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0844 - val_loss: 0.1334\n",
            "Epoch 256/300\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0864 - val_loss: 0.1280\n",
            "Epoch 257/300\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0841 - val_loss: 0.1227\n",
            "Epoch 258/300\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0862 - val_loss: 0.1274\n",
            "Epoch 259/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0836 - val_loss: 0.1301\n",
            "Epoch 260/300\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0842 - val_loss: 0.1276\n",
            "Epoch 261/300\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0834 - val_loss: 0.1237\n",
            "Epoch 262/300\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0851 - val_loss: 0.1307\n",
            "Epoch 263/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0839 - val_loss: 0.1350\n",
            "Epoch 264/300\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0861 - val_loss: 0.1262\n",
            "Epoch 265/300\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0828 - val_loss: 0.1250\n",
            "Epoch 266/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0859 - val_loss: 0.1367\n",
            "Epoch 267/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0868 - val_loss: 0.1385\n",
            "Epoch 268/300\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0880 - val_loss: 0.1259\n",
            "Epoch 269/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0879 - val_loss: 0.1247\n",
            "Epoch 270/300\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0840 - val_loss: 0.1403\n",
            "Epoch 271/300\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0898 - val_loss: 0.1352\n",
            "Epoch 272/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0856 - val_loss: 0.1265\n",
            "Epoch 273/300\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0895 - val_loss: 0.1246\n",
            "Epoch 274/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0839 - val_loss: 0.1413\n",
            "Epoch 275/300\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0911 - val_loss: 0.1375\n",
            "Epoch 276/300\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0874 - val_loss: 0.1247\n",
            "Epoch 277/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0846 - val_loss: 0.1280\n",
            "Epoch 278/300\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0829 - val_loss: 0.1289\n",
            "Epoch 279/300\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0832 - val_loss: 0.1250\n",
            "Epoch 280/300\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0830 - val_loss: 0.1239\n",
            "Epoch 281/300\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0831 - val_loss: 0.1253\n",
            "Epoch 282/300\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0830 - val_loss: 0.1290\n",
            "Epoch 283/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0833 - val_loss: 0.1276\n",
            "Epoch 284/300\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0829 - val_loss: 0.1243\n",
            "Epoch 285/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0845 - val_loss: 0.1356\n",
            "Epoch 286/300\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0863 - val_loss: 0.1360\n",
            "Epoch 287/300\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0865 - val_loss: 0.1241\n",
            "Epoch 288/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0831 - val_loss: 0.1266\n",
            "Epoch 289/300\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0912 - val_loss: 0.1285\n",
            "Epoch 290/300\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0830 - val_loss: 0.1352\n",
            "Epoch 291/300\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0859 - val_loss: 0.1292\n",
            "Epoch 292/300\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0832 - val_loss: 0.1256\n",
            "Epoch 293/300\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0877 - val_loss: 0.1301\n",
            "Epoch 294/300\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0834 - val_loss: 0.1353\n",
            "Epoch 295/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0860 - val_loss: 0.1280\n",
            "Epoch 296/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0828 - val_loss: 0.1264\n",
            "Epoch 297/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0904 - val_loss: 0.1266\n",
            "Epoch 298/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0827 - val_loss: 0.1378\n",
            "Epoch 299/300\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0877 - val_loss: 0.1359\n",
            "Epoch 300/300\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0864 - val_loss: 0.1245\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc5a5937bd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "Cl5hcp0bRAFI",
        "outputId": "3d7bcabd-3daa-4b7e-afad-23037f3539b6"
      },
      "source": [
        "y_pred = model.predict(valid_y)\n",
        "plt.scatter(valid_X, valid_y)\n",
        "plt.scatter(valid_X, y_pred, color='r')"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7fc5a5798650>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6lRnkBCLtzsJ"
      },
      "source": [
        "- underfit이 있는 것 같음\n",
        "- lr = 0.05 -> lr = 0.09\n",
        "- epochs = 300 -> epochs = 200"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q40lZz-FQ04o",
        "outputId": "4384a173-afac-4f38-c61a-54d5ee2ab25f"
      },
      "source": [
        "model = Sequential([\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "model.compile(loss = 'mae', optimizer=Adam(lr=0.09))\n",
        "\n",
        "model.fit(train_X,\n",
        "          train_y,\n",
        "          validation_data=(valid_X, valid_y),\n",
        "          epochs=200,\n",
        "          )\n"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "1/1 [==============================] - 0s 351ms/step - loss: 17.8225 - val_loss: 15.2812\n",
            "Epoch 2/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 17.1305 - val_loss: 14.7605\n",
            "Epoch 3/200\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 16.4385 - val_loss: 14.2398\n",
            "Epoch 4/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 15.7464 - val_loss: 13.7191\n",
            "Epoch 5/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 15.0544 - val_loss: 13.1984\n",
            "Epoch 6/200\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 14.3623 - val_loss: 12.6777\n",
            "Epoch 7/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 13.6703 - val_loss: 12.1570\n",
            "Epoch 8/200\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 12.9783 - val_loss: 11.6362\n",
            "Epoch 9/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 12.2862 - val_loss: 11.1155\n",
            "Epoch 10/200\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 11.5942 - val_loss: 10.5948\n",
            "Epoch 11/200\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 10.9022 - val_loss: 10.0741\n",
            "Epoch 12/200\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 10.2101 - val_loss: 9.5534\n",
            "Epoch 13/200\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 9.5181 - val_loss: 9.0327\n",
            "Epoch 14/200\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 8.8261 - val_loss: 8.5120\n",
            "Epoch 15/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 8.1340 - val_loss: 7.9912\n",
            "Epoch 16/200\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 7.4420 - val_loss: 7.4705\n",
            "Epoch 17/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 6.7500 - val_loss: 6.9498\n",
            "Epoch 18/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 6.0579 - val_loss: 6.4291\n",
            "Epoch 19/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 5.3659 - val_loss: 5.9084\n",
            "Epoch 20/200\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 4.6739 - val_loss: 5.3877\n",
            "Epoch 21/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 4.1148 - val_loss: 4.8817\n",
            "Epoch 22/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 3.7712 - val_loss: 4.3994\n",
            "Epoch 23/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 3.6108 - val_loss: 3.9856\n",
            "Epoch 24/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 3.5966 - val_loss: 3.7764\n",
            "Epoch 25/200\n",
            "1/1 [==============================] - 0s 373ms/step - loss: 3.6379 - val_loss: 3.5881\n",
            "Epoch 26/200\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 3.7289 - val_loss: 3.4241\n",
            "Epoch 27/200\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 3.8382 - val_loss: 3.2823\n",
            "Epoch 28/200\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 3.9317 - val_loss: 3.1632\n",
            "Epoch 29/200\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 4.0258 - val_loss: 3.0673\n",
            "Epoch 30/200\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 4.1106 - val_loss: 2.9924\n",
            "Epoch 31/200\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 4.1692 - val_loss: 2.9367\n",
            "Epoch 32/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 4.2039 - val_loss: 2.8984\n",
            "Epoch 33/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 4.2168 - val_loss: 2.8760\n",
            "Epoch 34/200\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 4.2099 - val_loss: 2.8681\n",
            "Epoch 35/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 4.1849 - val_loss: 2.8735\n",
            "Epoch 36/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 4.1435 - val_loss: 2.8909\n",
            "Epoch 37/200\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 4.0869 - val_loss: 2.9193\n",
            "Epoch 38/200\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 4.0166 - val_loss: 2.9579\n",
            "Epoch 39/200\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 3.9338 - val_loss: 3.0056\n",
            "Epoch 40/200\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 3.8394 - val_loss: 3.0617\n",
            "Epoch 41/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 3.7463 - val_loss: 3.1231\n",
            "Epoch 42/200\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 3.6554 - val_loss: 3.1867\n",
            "Epoch 43/200\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 3.5720 - val_loss: 3.2524\n",
            "Epoch 44/200\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 3.4863 - val_loss: 3.3200\n",
            "Epoch 45/200\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 3.3984 - val_loss: 3.3895\n",
            "Epoch 46/200\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 3.3248 - val_loss: 3.4548\n",
            "Epoch 47/200\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 3.2763 - val_loss: 3.5162\n",
            "Epoch 48/200\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 3.2300 - val_loss: 3.5710\n",
            "Epoch 49/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 3.2027 - val_loss: 3.6800\n",
            "Epoch 50/200\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 3.1757 - val_loss: 3.7898\n",
            "Epoch 51/200\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 3.1558 - val_loss: 3.8826\n",
            "Epoch 52/200\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3.1585 - val_loss: 3.9524\n",
            "Epoch 53/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 3.1582 - val_loss: 4.0013\n",
            "Epoch 54/200\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 3.1539 - val_loss: 4.0230\n",
            "Epoch 55/200\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 3.1500 - val_loss: 4.0199\n",
            "Epoch 56/200\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 3.1371 - val_loss: 3.9942\n",
            "Epoch 57/200\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 3.1162 - val_loss: 3.9480\n",
            "Epoch 58/200\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 3.0878 - val_loss: 3.8829\n",
            "Epoch 59/200\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 3.0526 - val_loss: 3.8007\n",
            "Epoch 60/200\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 3.0157 - val_loss: 3.7111\n",
            "Epoch 61/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.9805 - val_loss: 3.6148\n",
            "Epoch 62/200\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 2.9437 - val_loss: 3.5122\n",
            "Epoch 63/200\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.9056 - val_loss: 3.4039\n",
            "Epoch 64/200\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.8754 - val_loss: 3.3064\n",
            "Epoch 65/200\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.8570 - val_loss: 3.2187\n",
            "Epoch 66/200\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 2.8378 - val_loss: 3.1460\n",
            "Epoch 67/200\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 2.8180 - val_loss: 3.0981\n",
            "Epoch 68/200\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 2.7976 - val_loss: 3.0537\n",
            "Epoch 69/200\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.7766 - val_loss: 3.0126\n",
            "Epoch 70/200\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.7550 - val_loss: 2.9745\n",
            "Epoch 71/200\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.7330 - val_loss: 2.9389\n",
            "Epoch 72/200\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.7109 - val_loss: 2.9097\n",
            "Epoch 73/200\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.6884 - val_loss: 2.8863\n",
            "Epoch 74/200\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.6636 - val_loss: 2.8680\n",
            "Epoch 75/200\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.6382 - val_loss: 2.8506\n",
            "Epoch 76/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.6131 - val_loss: 2.8338\n",
            "Epoch 77/200\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 2.5877 - val_loss: 2.8177\n",
            "Epoch 78/200\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.5622 - val_loss: 2.8023\n",
            "Epoch 79/200\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 2.5364 - val_loss: 2.7873\n",
            "Epoch 80/200\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.5104 - val_loss: 2.7729\n",
            "Epoch 81/200\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 2.4842 - val_loss: 2.7679\n",
            "Epoch 82/200\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.4578 - val_loss: 2.7691\n",
            "Epoch 83/200\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.4313 - val_loss: 2.7712\n",
            "Epoch 84/200\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.4045 - val_loss: 2.7741\n",
            "Epoch 85/200\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.3776 - val_loss: 2.7778\n",
            "Epoch 86/200\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.3505 - val_loss: 2.7822\n",
            "Epoch 87/200\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.3279 - val_loss: 2.7780\n",
            "Epoch 88/200\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.3050 - val_loss: 2.7565\n",
            "Epoch 89/200\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.2815 - val_loss: 2.7194\n",
            "Epoch 90/200\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.2547 - val_loss: 2.6680\n",
            "Epoch 91/200\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.2268 - val_loss: 2.6132\n",
            "Epoch 92/200\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.1995 - val_loss: 2.5554\n",
            "Epoch 93/200\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.1732 - val_loss: 2.5043\n",
            "Epoch 94/200\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.1486 - val_loss: 2.4593\n",
            "Epoch 95/200\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 2.1237 - val_loss: 2.4199\n",
            "Epoch 96/200\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.0983 - val_loss: 2.3856\n",
            "Epoch 97/200\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.0725 - val_loss: 2.3558\n",
            "Epoch 98/200\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.0463 - val_loss: 2.3303\n",
            "Epoch 99/200\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.0198 - val_loss: 2.3085\n",
            "Epoch 100/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 1.9930 - val_loss: 2.2903\n",
            "Epoch 101/200\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 1.9658 - val_loss: 2.2751\n",
            "Epoch 102/200\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 1.9384 - val_loss: 2.2629\n",
            "Epoch 103/200\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 1.9121 - val_loss: 2.2431\n",
            "Epoch 104/200\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.8864 - val_loss: 2.2166\n",
            "Epoch 105/200\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 1.8602 - val_loss: 2.1839\n",
            "Epoch 106/200\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 1.8335 - val_loss: 2.1457\n",
            "Epoch 107/200\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 1.8063 - val_loss: 2.1024\n",
            "Epoch 108/200\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 1.7786 - val_loss: 2.0545\n",
            "Epoch 109/200\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 1.7515 - val_loss: 2.0128\n",
            "Epoch 110/200\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 1.7251 - val_loss: 1.9767\n",
            "Epoch 111/200\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 1.6984 - val_loss: 1.9456\n",
            "Epoch 112/200\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 1.6712 - val_loss: 1.9192\n",
            "Epoch 113/200\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 1.6437 - val_loss: 1.8970\n",
            "Epoch 114/200\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 1.6158 - val_loss: 1.8786\n",
            "Epoch 115/200\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 1.5893 - val_loss: 1.8531\n",
            "Epoch 116/200\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 1.5624 - val_loss: 1.8210\n",
            "Epoch 117/200\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 1.5351 - val_loss: 1.7831\n",
            "Epoch 118/200\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 1.5073 - val_loss: 1.7398\n",
            "Epoch 119/200\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 1.4790 - val_loss: 1.6916\n",
            "Epoch 120/200\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 1.4517 - val_loss: 1.6499\n",
            "Epoch 121/200\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 1.4246 - val_loss: 1.6141\n",
            "Epoch 122/200\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 1.3971 - val_loss: 1.5835\n",
            "Epoch 123/200\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 1.3692 - val_loss: 1.5578\n",
            "Epoch 124/200\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 1.3409 - val_loss: 1.5365\n",
            "Epoch 125/200\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1.3123 - val_loss: 1.5081\n",
            "Epoch 126/200\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 1.2848 - val_loss: 1.4732\n",
            "Epoch 127/200\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 1.2567 - val_loss: 1.4325\n",
            "Epoch 128/200\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 1.2285 - val_loss: 1.3977\n",
            "Epoch 129/200\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 1.2005 - val_loss: 1.3683\n",
            "Epoch 130/200\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 1.1721 - val_loss: 1.3324\n",
            "Epoch 131/200\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 1.1440 - val_loss: 1.3021\n",
            "Epoch 132/200\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 1.1158 - val_loss: 1.2654\n",
            "Epoch 133/200\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 1.0874 - val_loss: 1.2343\n",
            "Epoch 134/200\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 1.0591 - val_loss: 1.1969\n",
            "Epoch 135/200\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.0307 - val_loss: 1.1652\n",
            "Epoch 136/200\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.0022 - val_loss: 1.1272\n",
            "Epoch 137/200\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.9738 - val_loss: 1.0951\n",
            "Epoch 138/200\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.9451 - val_loss: 1.0683\n",
            "Epoch 139/200\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.9169 - val_loss: 1.0346\n",
            "Epoch 140/200\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.8883 - val_loss: 0.9947\n",
            "Epoch 141/200\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.8592 - val_loss: 0.9492\n",
            "Epoch 142/200\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.8310 - val_loss: 0.9104\n",
            "Epoch 143/200\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.8025 - val_loss: 0.8777\n",
            "Epoch 144/200\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.7735 - val_loss: 0.8504\n",
            "Epoch 145/200\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.7442 - val_loss: 0.8282\n",
            "Epoch 146/200\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.7154 - val_loss: 0.7985\n",
            "Epoch 147/200\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6868 - val_loss: 0.7621\n",
            "Epoch 148/200\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.6576 - val_loss: 0.7197\n",
            "Epoch 149/200\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6280 - val_loss: 0.6716\n",
            "Epoch 150/200\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.5994 - val_loss: 0.6324\n",
            "Epoch 151/200\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.5706 - val_loss: 0.5988\n",
            "Epoch 152/200\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5414 - val_loss: 0.5680\n",
            "Epoch 153/200\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.5117 - val_loss: 0.5445\n",
            "Epoch 154/200\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.4820 - val_loss: 0.5138\n",
            "Epoch 155/200\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.4529 - val_loss: 0.4762\n",
            "Epoch 156/200\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.4234 - val_loss: 0.4343\n",
            "Epoch 157/200\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.3940 - val_loss: 0.3994\n",
            "Epoch 158/200\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.3646 - val_loss: 0.3675\n",
            "Epoch 159/200\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.3348 - val_loss: 0.3403\n",
            "Epoch 160/200\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.3059 - val_loss: 0.3080\n",
            "Epoch 161/200\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.2765 - val_loss: 0.2693\n",
            "Epoch 162/200\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.2466 - val_loss: 0.2302\n",
            "Epoch 163/200\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.2164 - val_loss: 0.1945\n",
            "Epoch 164/200\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.1869 - val_loss: 0.1633\n",
            "Epoch 165/200\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.1570 - val_loss: 0.1435\n",
            "Epoch 166/200\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.1286 - val_loss: 0.1278\n",
            "Epoch 167/200\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.1044 - val_loss: 0.1216\n",
            "Epoch 168/200\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0927 - val_loss: 0.1296\n",
            "Epoch 169/200\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0854 - val_loss: 0.1382\n",
            "Epoch 170/200\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0876 - val_loss: 0.1376\n",
            "Epoch 171/200\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0879 - val_loss: 0.1319\n",
            "Epoch 172/200\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0951 - val_loss: 0.1345\n",
            "Epoch 173/200\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.1024 - val_loss: 0.1427\n",
            "Epoch 174/200\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.1088 - val_loss: 0.1497\n",
            "Epoch 175/200\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.1172 - val_loss: 0.1496\n",
            "Epoch 176/200\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.1210 - val_loss: 0.1475\n",
            "Epoch 177/200\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.1211 - val_loss: 0.1517\n",
            "Epoch 178/200\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.1257 - val_loss: 0.1525\n",
            "Epoch 179/200\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.1255 - val_loss: 0.1557\n",
            "Epoch 180/200\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.1328 - val_loss: 0.1508\n",
            "Epoch 181/200\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.1260 - val_loss: 0.1472\n",
            "Epoch 182/200\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.1225 - val_loss: 0.1528\n",
            "Epoch 183/200\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.1202 - val_loss: 0.1502\n",
            "Epoch 184/200\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.1131 - val_loss: 0.1415\n",
            "Epoch 185/200\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.1050 - val_loss: 0.1341\n",
            "Epoch 186/200\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.1009 - val_loss: 0.1325\n",
            "Epoch 187/200\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0963 - val_loss: 0.1384\n",
            "Epoch 188/200\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0909 - val_loss: 0.1406\n",
            "Epoch 189/200\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0899 - val_loss: 0.1279\n",
            "Epoch 190/200\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0850 - val_loss: 0.1263\n",
            "Epoch 191/200\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0869 - val_loss: 0.1323\n",
            "Epoch 192/200\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0843 - val_loss: 0.1322\n",
            "Epoch 193/200\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0851 - val_loss: 0.1224\n",
            "Epoch 194/200\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0841 - val_loss: 0.1213\n",
            "Epoch 195/200\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0888 - val_loss: 0.1232\n",
            "Epoch 196/200\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0857 - val_loss: 0.1345\n",
            "Epoch 197/200\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0889 - val_loss: 0.1266\n",
            "Epoch 198/200\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0870 - val_loss: 0.1205\n",
            "Epoch 199/200\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0888 - val_loss: 0.1296\n",
            "Epoch 200/200\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0881 - val_loss: 0.1339\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc5a5783850>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qfh4Xws1Q5wB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "outputId": "fdc53664-1611-4e5c-94fa-59218ad2c86d"
      },
      "source": [
        "y_pred = model.predict(valid_X)\n",
        "plt.scatter(valid_X, valid_y)\n",
        "plt.scatter(valid_X, y_pred, color='r')\n"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7fc5a6478250>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ma9qtbgQthDh"
      },
      "source": [
        "- SGD보다 어느정도 정확도가 높아짐"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAfOLlWRtj7p"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}