{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "week4_NCF.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Yn45WdAxBZN",
        "outputId": "cff6a0ec-cde5-436e-a5f4-f6b3dac8d0e1"
      },
      "source": [
        "%pip install Recommenders -q"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting Recommenders\n",
            "  Downloading recommenders-0.6.0-py3-none-manylinux1_x86_64.whl (233 kB)\n",
            "\u001b[K     |████████████████████████████████| 233 kB 14.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from Recommenders) (2.23.0)\n",
            "Requirement already satisfied: numba<1,>=0.38.1 in /usr/local/lib/python3.7/dist-packages (from Recommenders) (0.51.2)\n",
            "Collecting transformers<5,>=2.5.0\n",
            "  Downloading transformers-4.9.2-py3-none-any.whl (2.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.6 MB 61.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib<4,>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from Recommenders) (3.2.2)\n",
            "Collecting pydocumentdb>=2.3.3<3\n",
            "  Downloading pydocumentdb-2.3.5-py3-none-any.whl (93 kB)\n",
            "\u001b[K     |████████████████████████████████| 93 kB 2.8 MB/s \n",
            "\u001b[?25hCollecting cornac<2,>=1.1.2\n",
            "  Downloading cornac-1.13.5-cp37-cp37m-manylinux1_x86_64.whl (12.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.4 MB 61.2 MB/s \n",
            "\u001b[?25hCollecting scikit-surprise<=1.1.1,>=0.19.1\n",
            "  Downloading scikit-surprise-1.1.1.tar.gz (11.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.8 MB 15.4 MB/s \n",
            "\u001b[?25hCollecting pyyaml<6,>=5.4.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 63.9 MB/s \n",
            "\u001b[?25hCollecting lightfm<2,>=1.15\n",
            "  Downloading lightfm-1.16.tar.gz (310 kB)\n",
            "\u001b[K     |████████████████████████████████| 310 kB 78.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy<2,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from Recommenders) (1.4.1)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.7/dist-packages (from Recommenders) (1.3.3)\n",
            "Collecting pymanopt<1,>=0.2.5\n",
            "  Downloading pymanopt-0.2.5-py3-none-any.whl (59 kB)\n",
            "\u001b[K     |████████████████████████████████| 59 kB 7.8 MB/s \n",
            "\u001b[?25hCollecting category-encoders<2,>=1.3.0\n",
            "  Downloading category_encoders-1.3.0-py2.py3-none-any.whl (61 kB)\n",
            "\u001b[K     |████████████████████████████████| 61 kB 10.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: bottleneck<2,>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from Recommenders) (1.3.2)\n",
            "Requirement already satisfied: jinja2<3,>=2 in /usr/local/lib/python3.7/dist-packages (from Recommenders) (2.11.3)\n",
            "Requirement already satisfied: seaborn<1,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from Recommenders) (0.11.1)\n",
            "Requirement already satisfied: tqdm<5,>=4.31.1 in /usr/local/lib/python3.7/dist-packages (from Recommenders) (4.62.0)\n",
            "Collecting nltk<4,>=3.4\n",
            "  Downloading nltk-3.6.2-py3-none-any.whl (1.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 52.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: lightgbm<3,>=2.2.1 in /usr/local/lib/python3.7/dist-packages (from Recommenders) (2.2.3)\n",
            "Requirement already satisfied: pandas<2,>1.0.3 in /usr/local/lib/python3.7/dist-packages (from Recommenders) (1.1.5)\n",
            "Requirement already satisfied: scikit-learn<1,>=0.22.1 in /usr/local/lib/python3.7/dist-packages (from Recommenders) (0.22.2.post1)\n",
            "Requirement already satisfied: numpy>=1.14 in /usr/local/lib/python3.7/dist-packages (from Recommenders) (1.19.5)\n",
            "Collecting memory-profiler<1,>=0.54.0\n",
            "  Downloading memory_profiler-0.58.0.tar.gz (36 kB)\n",
            "Requirement already satisfied: patsy>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from category-encoders<2,>=1.3.0->Recommenders) (0.5.1)\n",
            "Requirement already satisfied: statsmodels>=0.6.1 in /usr/local/lib/python3.7/dist-packages (from category-encoders<2,>=1.3.0->Recommenders) (0.10.2)\n",
            "Collecting powerlaw\n",
            "  Downloading powerlaw-1.5-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2<3,>=2->Recommenders) (2.0.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib<4,>=2.2.2->Recommenders) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib<4,>=2.2.2->Recommenders) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib<4,>=2.2.2->Recommenders) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib<4,>=2.2.2->Recommenders) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib<4,>=2.2.2->Recommenders) (1.15.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from memory-profiler<1,>=0.54.0->Recommenders) (5.4.8)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk<4,>=3.4->Recommenders) (7.1.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from nltk<4,>=3.4->Recommenders) (2019.12.20)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk<4,>=3.4->Recommenders) (1.0.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba<1,>=0.38.1->Recommenders) (57.4.0)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba<1,>=0.38.1->Recommenders) (0.34.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas<2,>1.0.3->Recommenders) (2018.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->Recommenders) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->Recommenders) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->Recommenders) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->Recommenders) (2.10)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<5,>=2.5.0->Recommenders) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers<5,>=2.5.0->Recommenders) (21.0)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 70.3 MB/s \n",
            "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 56.1 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub==0.0.12\n",
            "  Downloading huggingface_hub-0.0.12-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers<5,>=2.5.0->Recommenders) (4.6.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers<5,>=2.5.0->Recommenders) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers<5,>=2.5.0->Recommenders) (3.5.0)\n",
            "Requirement already satisfied: mpmath in /usr/local/lib/python3.7/dist-packages (from powerlaw->cornac<2,>=1.1.2->Recommenders) (1.2.1)\n",
            "Building wheels for collected packages: lightfm, memory-profiler, scikit-surprise\n",
            "  Building wheel for lightfm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lightfm: filename=lightfm-1.16-cp37-cp37m-linux_x86_64.whl size=706134 sha256=4d81bf383a18fda7f21ff9a9de29bee5f55712e45736d3db36fd1be6e6991226\n",
            "  Stored in directory: /root/.cache/pip/wheels/f8/56/28/5772a3bd3413d65f03aa452190b00898b680b10028a1021914\n",
            "  Building wheel for memory-profiler (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for memory-profiler: filename=memory_profiler-0.58.0-py3-none-any.whl size=30190 sha256=f3a15a57768fb8691228ff8653e6a99b255f059dfc9903c57e5e9b59f017e1bb\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/19/d5/8cad06661aec65a04a0d6785b1a5ad035cb645b1772a4a0882\n",
            "  Building wheel for scikit-surprise (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.1-cp37-cp37m-linux_x86_64.whl size=1619431 sha256=4e6febb87fda978bb68cddb4b422908c4b9ba53e6fb5fa3c10a6b71f64f72cdf\n",
            "  Stored in directory: /root/.cache/pip/wheels/76/44/74/b498c42be47b2406bd27994e16c5188e337c657025ab400c1c\n",
            "Successfully built lightfm memory-profiler scikit-surprise\n",
            "Installing collected packages: tokenizers, sacremoses, pyyaml, powerlaw, huggingface-hub, transformers, scikit-surprise, pymanopt, pydocumentdb, nltk, memory-profiler, lightfm, cornac, category-encoders, Recommenders\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "Successfully installed Recommenders-0.6.0 category-encoders-1.3.0 cornac-1.13.5 huggingface-hub-0.0.12 lightfm-1.16 memory-profiler-0.58.0 nltk-3.6.2 powerlaw-1.5 pydocumentdb-2.3.5 pymanopt-0.2.5 pyyaml-5.4.1 sacremoses-0.0.45 scikit-surprise-1.1.1 tokenizers-0.10.3 transformers-4.9.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LODk37VHxMhO"
      },
      "source": [
        "import sys\n",
        "import time\n",
        "import os\n",
        "import shutil\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "%tensorflow_version 1.x\n",
        "\n",
        "import tensorflow as tf\n",
        "from reco_utils.recommender.ncf.ncf_singlenode import NCF\n",
        "from reco_utils.recommender.ncf.dataset import Dataset as NCFDataset\n",
        "from reco_utils.dataset import movielens\n",
        "from reco_utils.dataset.python_splitters import python_chrono_split\n",
        "from reco_utils.evaluation.python_evaluation import (rmse, mae, rsquared, exp_var, map_at_k, ndcg_at_k,\n",
        "                                                     recall_at_k, precision_at_k, get_top_k_items)\n",
        "from reco_utils.common.constants import SEED as DEFAULT_SEED"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xc1GfWR8xvsX",
        "outputId": "58b279f2-724b-425d-e2e0-6aff49cd07d3"
      },
      "source": [
        "# top k 아이템 설정\n",
        "TOP_K = 10\n",
        "\n",
        "# MovieLens data size: 100k, 1m, 10m, 20m 중 제일 작은 것 가져오기\n",
        "MOVIELENS_DATA_SIZE = '100k'\n",
        "\n",
        "# Model Params\n",
        "EPOCHS = 100\n",
        "BATCH_SIZE = 256\n",
        "\n",
        "SEED = DEFAULT_SEED\n",
        "\n",
        "# loading movie lens data\n",
        "df = movielens.load_pandas_df(size=MOVIELENS_DATA_SIZE, header=['userID', 'itemID', 'rating', 'timestamp'])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4.81k/4.81k [00:00<00:00, 5.24kKB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmKwS1RQyFJm"
      },
      "source": [
        "# 75% 비중으로 나누기\n",
        "train, test = python_chrono_split(df, 0.75)\n",
        "\n",
        "# userid, itemid, rating이 있는 데이터만 가져옴\n",
        "data = NCFDataset(train=train, test=test, seed=SEED)\n",
        "\n",
        "tf.compat.v1.disable_eager_execution()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "id": "tq8x3dquyRBd",
        "outputId": "48d9d573-834c-4bda-c3b2-8e938858cac3"
      },
      "source": [
        "# 모델 정의 및 학습, 예측\n",
        "model = NCF(n_users=data.n_users, n_items=data.n_items, model_type='NeuMF', n_factors=4,\n",
        "            layer_sizes=[16,8,4], n_epochs=EPOCHS, batch_size=BATCH_SIZE, learning_rate=1e-3,\n",
        "            verbose=10, seed=SEED)\n",
        "# n_factors: latent space의 차원 수\n",
        "# layer_sizes: MLP 레이어 수\n",
        "\n",
        "model.fit(data)\n",
        "\n",
        "predictions = [[row.userID, row.itemID, model.predict(row.userID, row.itemID)]\n",
        "               for (_, row) in test.iterrows()]\n",
        "\n",
        "# 예측값 저장\n",
        "predictions = pd.DataFrame(predictions, columns=['userID', 'itemID', 'prediction'])\n",
        "predictions.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/layers/python/layers/layers.py:1866: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/losses/losses_impl.py:121: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userID</th>\n",
              "      <th>itemID</th>\n",
              "      <th>prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>149.0</td>\n",
              "      <td>0.048069</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>88.0</td>\n",
              "      <td>0.625640</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>101.0</td>\n",
              "      <td>0.079044</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>110.0</td>\n",
              "      <td>0.078758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>103.0</td>\n",
              "      <td>0.004996</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   userID  itemID  prediction\n",
              "0     1.0   149.0    0.048069\n",
              "1     1.0    88.0    0.625640\n",
              "2     1.0   101.0    0.079044\n",
              "3     1.0   110.0    0.078758\n",
              "4     1.0   103.0    0.004996"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MshZxFnWyUOP"
      },
      "source": [
        "# 성능 확인\n",
        "users, items, preds = [], [], []\n",
        "item = list(train.itemID.unique())\n",
        "for user in train.userID.unique():\n",
        "    user = [user] * len(item)\n",
        "    users.extend(user)\n",
        "    items.extend(item)\n",
        "    preds.extend(list(model.predict(user, item, is_list=True)))\n",
        "\n",
        "all_predictions = pd.DataFrame(data={'userID': users, 'itemID': items, 'prediction': preds})\n",
        "\n",
        "merged = pd.merge(train, all_predictions, on=['userID', 'itemID'], how='outer')\n",
        "all_predictions = merged[merged.rating.isnull()].drop('rating', axis=1)\n",
        "\n",
        "eval_map = map_at_k(test, all_predictions, col_prediction='prediction', k=TOP_K)\n",
        "eval_ndcg = ndcg_at_k(test, all_predictions, col_prediction='prediction', k=TOP_K)\n",
        "eval_precision = precision_at_k(test, all_predictions, col_prediction='prediction', k=TOP_K)\n",
        "eval_recall = recall_at_k(test, all_predictions, col_prediction='prediction', k=TOP_K)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ONtBRZZ5zMs",
        "outputId": "6fcd6686-abef-4ba5-8538-8d9e0f6e1de2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "eval_ndcg"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.1906842374042988"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    }
  ]
}